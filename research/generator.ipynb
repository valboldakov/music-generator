{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fractions\n",
    "import os\n",
    "import music21\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from keras_preprocessing.text import Tokenizer\n",
    "from keras_self_attention import SeqSelfAttention\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow import random\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.python.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "\n",
    "RANDOM_STATE: int = 151"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class ChordGeneratorMusicModel:\n",
    "    def __init__(self, seq_len: int, chords_vocab_size: int):\n",
    "        random.set_seed(RANDOM_STATE)\n",
    "        chords_input = Input(shape=(seq_len, 1))\n",
    "        bilstm = Bidirectional(LSTM(512, return_sequences=True))(chords_input)\n",
    "        attention = SeqSelfAttention(attention_activation=\"sigmoid\")(bilstm)\n",
    "        dropout = Dropout(0.3)(attention)\n",
    "        lstm = LSTM(512, return_sequences=True)(dropout)\n",
    "        dropout = Dropout(0.3)(lstm)\n",
    "        pool = GlobalAveragePooling1D()(dropout)\n",
    "        dense = Dense(256)(pool)\n",
    "        chord_output = Dense(chords_vocab_size, activation=\"softmax\")(dense)\n",
    "        self._model = Model(chords_input, chord_output)\n",
    "        self._model.compile(loss='sparse_categorical_crossentropy', optimizer='rmsprop', metrics=[\"accuracy\"])\n",
    "\n",
    "    def fit(self, train_x, train_y, **kwargs):\n",
    "        return self._model.fit(train_x, train_y, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ChordDurationSeq</th>\n",
       "      <th>NextChordDuration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rest#4.5 0#1.25 8#0.25 5#4.5 8#1.25 0#0.25 5#1...</td>\n",
       "      <td>rest#0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0#1.25 8#0.25 5#4.5 8#1.25 0#0.25 5#1.5 8#1.25...</td>\n",
       "      <td>1#0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8#0.25 5#4.5 8#1.25 0#0.25 5#1.5 8#1.25 0#0.25...</td>\n",
       "      <td>rest#0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5#4.5 8#1.25 0#0.25 5#1.5 8#1.25 0#0.25 5#1.5 ...</td>\n",
       "      <td>1#0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8#1.25 0#0.25 5#1.5 8#1.25 0#0.25 5#1.5 5|8#1....</td>\n",
       "      <td>rest#0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63777</th>\n",
       "      <td>3|7|10#0.25 3|7|10#0.25 3|7#1/12 7|8|0|3#1/6 7...</td>\n",
       "      <td>10#0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63778</th>\n",
       "      <td>3|7|10#0.25 3|7#1/12 7|8|0|3#1/6 7|10#0.25 6|9...</td>\n",
       "      <td>3|7|10#1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63779</th>\n",
       "      <td>3|7#1/12 7|8|0|3#1/6 7|10#0.25 6|9#0.25 7|10#0...</td>\n",
       "      <td>rest#0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63780</th>\n",
       "      <td>7|8|0|3#1/6 7|10#0.25 6|9#0.25 7|10#0.25 10|3#...</td>\n",
       "      <td>2|5|8|10#1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63781</th>\n",
       "      <td>7|10#0.25 6|9#0.25 7|10#0.25 10|3#0.25 3|7#0.2...</td>\n",
       "      <td>rest#0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>63782 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        ChordDurationSeq NextChordDuration\n",
       "0      rest#4.5 0#1.25 8#0.25 5#4.5 8#1.25 0#0.25 5#1...         rest#0.25\n",
       "1      0#1.25 8#0.25 5#4.5 8#1.25 0#0.25 5#1.5 8#1.25...            1#0.25\n",
       "2      8#0.25 5#4.5 8#1.25 0#0.25 5#1.5 8#1.25 0#0.25...         rest#0.25\n",
       "3      5#4.5 8#1.25 0#0.25 5#1.5 8#1.25 0#0.25 5#1.5 ...            1#0.25\n",
       "4      8#1.25 0#0.25 5#1.5 8#1.25 0#0.25 5#1.5 5|8#1....         rest#0.25\n",
       "...                                                  ...               ...\n",
       "63777  3|7|10#0.25 3|7|10#0.25 3|7#1/12 7|8|0|3#1/6 7...           10#0.25\n",
       "63778  3|7|10#0.25 3|7#1/12 7|8|0|3#1/6 7|10#0.25 6|9...        3|7|10#1.0\n",
       "63779  3|7#1/12 7|8|0|3#1/6 7|10#0.25 6|9#0.25 7|10#0...          rest#0.5\n",
       "63780  7|8|0|3#1/6 7|10#0.25 6|9#0.25 7|10#0.25 10|3#...      2|5|8|10#1.0\n",
       "63781  7|10#0.25 6|9#0.25 7|10#0.25 10|3#0.25 3|7#0.2...          rest#0.5\n",
       "\n",
       "[63782 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples: pd.DataFrame = pd.read_csv(\"./data/beethoven_samples.csv\")\n",
    "samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator_seq_len: int = len(samples[\"ChordDurationSeq\"][0].split(\" \"))\n",
    "generator_seq_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = samples[\"ChordDurationSeq\"]\n",
    "Y = samples[\"NextChordDuration\"]\n",
    "\n",
    "tokenizer: Tokenizer = Tokenizer(filters=\"\")\n",
    "tokenizer.fit_on_texts(X)\n",
    "tokenizer.fit_on_texts(Y)\n",
    "\n",
    "X = np.array([z for sublist in tokenizer.texts_to_sequences(X) for z in sublist]).reshape((-1, 100))\n",
    "Y = np.array([z for sublist in tokenizer.texts_to_sequences(Y) for z in sublist])\n",
    "scaler: StandardScaler = StandardScaler()\n",
    "X = scaler.fit_transform(X.reshape(-1, 1)).reshape(-1, generator_seq_len, 1)\n",
    "train_x, test_x, train_y, test_y = train_test_split(X, Y, shuffle=True, random_state=RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/170\n",
      "748/748 [==============================] - 34s 46ms/step - loss: 6.3180 - accuracy: 0.0246 - val_loss: 6.1778 - val_accuracy: 0.0282\n",
      "Epoch 2/170\n",
      "748/748 [==============================] - 34s 45ms/step - loss: 6.1054 - accuracy: 0.0293 - val_loss: 6.0994 - val_accuracy: 0.0310\n",
      "Epoch 3/170\n",
      "748/748 [==============================] - 34s 45ms/step - loss: 6.0067 - accuracy: 0.0320 - val_loss: 6.0423 - val_accuracy: 0.0315\n",
      "Epoch 4/170\n",
      "748/748 [==============================] - 34s 45ms/step - loss: 5.9332 - accuracy: 0.0356 - val_loss: 5.9862 - val_accuracy: 0.0398\n",
      "Epoch 5/170\n",
      "748/748 [==============================] - 34s 45ms/step - loss: 5.8479 - accuracy: 0.0423 - val_loss: 5.9345 - val_accuracy: 0.0408\n",
      "Epoch 6/170\n",
      "748/748 [==============================] - 34s 45ms/step - loss: 5.7484 - accuracy: 0.0513 - val_loss: 5.8356 - val_accuracy: 0.0514\n",
      "Epoch 7/170\n",
      "748/748 [==============================] - 34s 46ms/step - loss: 5.6110 - accuracy: 0.0619 - val_loss: 5.6693 - val_accuracy: 0.0647\n",
      "Epoch 8/170\n",
      "748/748 [==============================] - 34s 46ms/step - loss: 5.4534 - accuracy: 0.0782 - val_loss: 5.6468 - val_accuracy: 0.0689\n",
      "Epoch 9/170\n",
      "748/748 [==============================] - 34s 46ms/step - loss: 5.2937 - accuracy: 0.0924 - val_loss: 5.4585 - val_accuracy: 0.0815\n",
      "Epoch 10/170\n",
      "747/748 [============================>.] - ETA: 0s - loss: 5.1193 - accuracy: 0.1110\n",
      "Epoch 00010: saving model to /home/jupyter/workspace/Documents/music-generator/research/models/shfull-generator-10-5.119484901428223\n",
      "WARNING:tensorflow:From /home/jupyter/.local/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py:1817: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "INFO:tensorflow:Assets written to: /home/jupyter/workspace/Documents/music-generator/research/models/shfull-generator-10-5.119484901428223/assets\n",
      "748/748 [==============================] - 49s 66ms/step - loss: 5.1195 - accuracy: 0.1110 - val_loss: 5.2983 - val_accuracy: 0.1050\n",
      "Epoch 11/170\n",
      "748/748 [==============================] - 34s 45ms/step - loss: 4.9554 - accuracy: 0.1310 - val_loss: 5.1957 - val_accuracy: 0.1178\n",
      "Epoch 12/170\n",
      "748/748 [==============================] - 34s 46ms/step - loss: 4.8018 - accuracy: 0.1488 - val_loss: 5.0864 - val_accuracy: 0.1331\n",
      "Epoch 13/170\n",
      "748/748 [==============================] - 34s 46ms/step - loss: 4.6935 - accuracy: 0.1645 - val_loss: 5.0427 - val_accuracy: 0.1414\n",
      "Epoch 14/170\n",
      "748/748 [==============================] - 34s 46ms/step - loss: 4.7209 - accuracy: 0.1737 - val_loss: 5.1693 - val_accuracy: 0.1500\n",
      "Epoch 15/170\n",
      "748/748 [==============================] - 34s 46ms/step - loss: 4.7214 - accuracy: 0.1914 - val_loss: 5.1618 - val_accuracy: 0.1568\n",
      "Epoch 16/170\n",
      "748/748 [==============================] - 34s 46ms/step - loss: 4.6815 - accuracy: 0.2043 - val_loss: 5.1191 - val_accuracy: 0.1666\n",
      "Epoch 17/170\n",
      "748/748 [==============================] - 34s 46ms/step - loss: 4.6199 - accuracy: 0.2124 - val_loss: 5.0995 - val_accuracy: 0.1762\n",
      "Epoch 18/170\n",
      "748/748 [==============================] - 34s 46ms/step - loss: 4.5641 - accuracy: 0.2239 - val_loss: 5.1243 - val_accuracy: 0.1758\n",
      "Epoch 19/170\n",
      "748/748 [==============================] - 34s 46ms/step - loss: 4.5153 - accuracy: 0.2342 - val_loss: 5.0904 - val_accuracy: 0.1826\n",
      "Epoch 20/170\n",
      "747/748 [============================>.] - ETA: 0s - loss: 4.4612 - accuracy: 0.2431\n",
      "Epoch 00020: saving model to /home/jupyter/workspace/Documents/music-generator/research/models/shfull-generator-20-4.46200704574585\n",
      "INFO:tensorflow:Assets written to: /home/jupyter/workspace/Documents/music-generator/research/models/shfull-generator-20-4.46200704574585/assets\n",
      "748/748 [==============================] - 49s 66ms/step - loss: 4.4620 - accuracy: 0.2430 - val_loss: 5.0854 - val_accuracy: 0.1905\n",
      "Epoch 21/170\n",
      "748/748 [==============================] - 34s 46ms/step - loss: 4.4264 - accuracy: 0.2527 - val_loss: 5.0641 - val_accuracy: 0.1965\n",
      "Epoch 22/170\n",
      "748/748 [==============================] - 34s 46ms/step - loss: 4.3963 - accuracy: 0.2571 - val_loss: 5.0487 - val_accuracy: 0.1959\n",
      "Epoch 23/170\n",
      "748/748 [==============================] - 34s 46ms/step - loss: 4.3500 - accuracy: 0.2708 - val_loss: 5.0570 - val_accuracy: 0.2019\n",
      "Epoch 24/170\n",
      "748/748 [==============================] - 34s 46ms/step - loss: 4.3174 - accuracy: 0.2760 - val_loss: 5.0157 - val_accuracy: 0.2053\n",
      "Epoch 25/170\n",
      "748/748 [==============================] - 34s 46ms/step - loss: 4.2931 - accuracy: 0.2834 - val_loss: 5.0557 - val_accuracy: 0.2048\n",
      "Epoch 26/170\n",
      "748/748 [==============================] - 34s 46ms/step - loss: 4.2514 - accuracy: 0.2906 - val_loss: 5.0212 - val_accuracy: 0.2128\n",
      "Epoch 27/170\n",
      "748/748 [==============================] - 34s 46ms/step - loss: 4.2203 - accuracy: 0.2987 - val_loss: 5.0018 - val_accuracy: 0.2139\n",
      "Epoch 28/170\n",
      "748/748 [==============================] - 34s 46ms/step - loss: 4.1918 - accuracy: 0.3046 - val_loss: 5.0851 - val_accuracy: 0.2022\n",
      "Epoch 29/170\n",
      "748/748 [==============================] - 34s 46ms/step - loss: 4.1470 - accuracy: 0.3142 - val_loss: 4.9862 - val_accuracy: 0.2191\n",
      "Epoch 30/170\n",
      "747/748 [============================>.] - ETA: 0s - loss: 4.1210 - accuracy: 0.3202\n",
      "Epoch 00030: saving model to /home/jupyter/workspace/Documents/music-generator/research/models/shfull-generator-30-4.121154308319092\n",
      "INFO:tensorflow:Assets written to: /home/jupyter/workspace/Documents/music-generator/research/models/shfull-generator-30-4.121154308319092/assets\n",
      "748/748 [==============================] - 49s 66ms/step - loss: 4.1212 - accuracy: 0.3202 - val_loss: 5.0098 - val_accuracy: 0.2246\n",
      "Epoch 31/170\n",
      "748/748 [==============================] - 34s 46ms/step - loss: 4.0904 - accuracy: 0.3268 - val_loss: 5.0306 - val_accuracy: 0.2207\n",
      "Epoch 32/170\n",
      "748/748 [==============================] - 34s 46ms/step - loss: 4.0674 - accuracy: 0.3320 - val_loss: 4.9598 - val_accuracy: 0.2372\n",
      "Epoch 33/170\n",
      "748/748 [==============================] - 34s 46ms/step - loss: 4.0263 - accuracy: 0.3398 - val_loss: 4.9440 - val_accuracy: 0.2428\n",
      "Epoch 34/170\n",
      "748/748 [==============================] - 34s 46ms/step - loss: 3.9732 - accuracy: 0.3534 - val_loss: 4.9820 - val_accuracy: 0.2320\n",
      "Epoch 35/170\n",
      "748/748 [==============================] - 34s 46ms/step - loss: 3.9475 - accuracy: 0.3583 - val_loss: 4.9341 - val_accuracy: 0.2454\n",
      "Epoch 36/170\n",
      "748/748 [==============================] - 34s 46ms/step - loss: 3.9030 - accuracy: 0.3658 - val_loss: 4.9534 - val_accuracy: 0.2369\n",
      "Epoch 37/170\n",
      "748/748 [==============================] - 34s 46ms/step - loss: 3.8822 - accuracy: 0.3695 - val_loss: 4.9133 - val_accuracy: 0.2530\n",
      "Epoch 38/170\n",
      "748/748 [==============================] - 34s 46ms/step - loss: 3.8341 - accuracy: 0.3764 - val_loss: 4.8972 - val_accuracy: 0.2594\n",
      "Epoch 39/170\n",
      "748/748 [==============================] - 34s 46ms/step - loss: 3.7974 - accuracy: 0.3864 - val_loss: 4.9066 - val_accuracy: 0.2571\n",
      "Epoch 40/170\n",
      "747/748 [============================>.] - ETA: 0s - loss: 3.7712 - accuracy: 0.3908\n",
      "Epoch 00040: saving model to /home/jupyter/workspace/Documents/music-generator/research/models/shfull-generator-40-3.772040843963623\n",
      "INFO:tensorflow:Assets written to: /home/jupyter/workspace/Documents/music-generator/research/models/shfull-generator-40-3.772040843963623/assets\n",
      "748/748 [==============================] - 49s 65ms/step - loss: 3.7720 - accuracy: 0.3907 - val_loss: 4.8589 - val_accuracy: 0.2640\n",
      "Epoch 41/170\n",
      "748/748 [==============================] - 34s 46ms/step - loss: 3.7291 - accuracy: 0.3965 - val_loss: 4.8780 - val_accuracy: 0.2649\n",
      "Epoch 42/170\n",
      "748/748 [==============================] - 34s 46ms/step - loss: 3.6937 - accuracy: 0.4052 - val_loss: 4.9061 - val_accuracy: 0.2601\n",
      "Epoch 43/170\n",
      "748/748 [==============================] - 34s 46ms/step - loss: 3.6673 - accuracy: 0.4100 - val_loss: 4.8969 - val_accuracy: 0.2612\n",
      "Epoch 44/170\n",
      "748/748 [==============================] - 34s 46ms/step - loss: 3.6203 - accuracy: 0.4176 - val_loss: 4.8621 - val_accuracy: 0.2686\n",
      "Epoch 45/170\n",
      "748/748 [==============================] - 34s 46ms/step - loss: 3.5639 - accuracy: 0.4280 - val_loss: 4.8821 - val_accuracy: 0.2674\n",
      "Epoch 46/170\n",
      "748/748 [==============================] - 34s 46ms/step - loss: 3.5290 - accuracy: 0.4365 - val_loss: 4.8529 - val_accuracy: 0.2814\n",
      "Epoch 47/170\n",
      "748/748 [==============================] - 34s 46ms/step - loss: 3.5014 - accuracy: 0.4387 - val_loss: 4.8638 - val_accuracy: 0.2764\n",
      "Epoch 48/170\n",
      "748/748 [==============================] - 34s 46ms/step - loss: 3.4682 - accuracy: 0.4467 - val_loss: 4.8896 - val_accuracy: 0.2783\n",
      "Epoch 49/170\n",
      "748/748 [==============================] - 34s 46ms/step - loss: 3.4428 - accuracy: 0.4542 - val_loss: 4.8089 - val_accuracy: 0.2877\n",
      "Epoch 50/170\n",
      "747/748 [============================>.] - ETA: 0s - loss: 3.4148 - accuracy: 0.4590\n",
      "Epoch 00050: saving model to /home/jupyter/workspace/Documents/music-generator/research/models/shfull-generator-50-3.4150404930114746\n",
      "INFO:tensorflow:Assets written to: /home/jupyter/workspace/Documents/music-generator/research/models/shfull-generator-50-3.4150404930114746/assets\n",
      "748/748 [==============================] - 49s 66ms/step - loss: 3.4150 - accuracy: 0.4590 - val_loss: 4.7903 - val_accuracy: 0.2940\n",
      "Epoch 51/170\n",
      "748/748 [==============================] - 34s 46ms/step - loss: 3.3757 - accuracy: 0.4670 - val_loss: 4.7812 - val_accuracy: 0.2968\n",
      "Epoch 52/170\n",
      "748/748 [==============================] - 34s 46ms/step - loss: 3.3475 - accuracy: 0.4747 - val_loss: 4.7962 - val_accuracy: 0.2898\n",
      "Epoch 53/170\n",
      "748/748 [==============================] - 35s 46ms/step - loss: 3.3200 - accuracy: 0.4792 - val_loss: 4.7731 - val_accuracy: 0.3011\n",
      "Epoch 54/170\n",
      "748/748 [==============================] - 34s 46ms/step - loss: 3.3002 - accuracy: 0.4824 - val_loss: 4.7743 - val_accuracy: 0.3000\n",
      "Epoch 55/170\n",
      "748/748 [==============================] - 34s 46ms/step - loss: 3.2541 - accuracy: 0.4931 - val_loss: 4.8547 - val_accuracy: 0.2882\n",
      "Epoch 56/170\n",
      "748/748 [==============================] - 34s 46ms/step - loss: 3.2363 - accuracy: 0.4961 - val_loss: 4.7710 - val_accuracy: 0.3139\n",
      "Epoch 57/170\n",
      "748/748 [==============================] - 34s 46ms/step - loss: 3.2022 - accuracy: 0.5020 - val_loss: 4.8055 - val_accuracy: 0.3043\n",
      "Epoch 58/170\n",
      "748/748 [==============================] - 34s 46ms/step - loss: 3.1674 - accuracy: 0.5110 - val_loss: 4.7768 - val_accuracy: 0.3062\n",
      "Epoch 59/170\n",
      "748/748 [==============================] - 34s 46ms/step - loss: 3.1600 - accuracy: 0.5136 - val_loss: 4.7856 - val_accuracy: 0.3100\n",
      "Epoch 60/170\n",
      "747/748 [============================>.] - ETA: 0s - loss: 3.1180 - accuracy: 0.5184\n",
      "Epoch 00060: saving model to /home/jupyter/workspace/Documents/music-generator/research/models/shfull-generator-60-3.1175968647003174\n",
      "INFO:tensorflow:Assets written to: /home/jupyter/workspace/Documents/music-generator/research/models/shfull-generator-60-3.1175968647003174/assets\n",
      "748/748 [==============================] - 49s 65ms/step - loss: 3.1176 - accuracy: 0.5185 - val_loss: 4.7687 - val_accuracy: 0.3130\n",
      "Epoch 61/170\n",
      "748/748 [==============================] - 34s 46ms/step - loss: 3.0872 - accuracy: 0.5253 - val_loss: 4.7654 - val_accuracy: 0.3187\n",
      "Epoch 62/170\n",
      "748/748 [==============================] - 34s 46ms/step - loss: 3.0557 - accuracy: 0.5319 - val_loss: 4.7485 - val_accuracy: 0.3195\n",
      "Epoch 63/170\n",
      "748/748 [==============================] - 34s 46ms/step - loss: 3.0387 - accuracy: 0.5345 - val_loss: 4.7837 - val_accuracy: 0.3193\n",
      "Epoch 64/170\n",
      "748/748 [==============================] - 34s 46ms/step - loss: 3.0146 - accuracy: 0.5440 - val_loss: 4.7323 - val_accuracy: 0.3219\n",
      "Epoch 65/170\n",
      "748/748 [==============================] - 34s 46ms/step - loss: 2.9820 - accuracy: 0.5478 - val_loss: 4.7298 - val_accuracy: 0.3247\n",
      "Epoch 66/170\n",
      "748/748 [==============================] - 34s 46ms/step - loss: 2.9658 - accuracy: 0.5497 - val_loss: 4.7872 - val_accuracy: 0.3112\n",
      "Epoch 67/170\n",
      "748/748 [==============================] - 34s 46ms/step - loss: 2.9390 - accuracy: 0.5581 - val_loss: 4.7602 - val_accuracy: 0.3233\n",
      "Epoch 68/170\n",
      "748/748 [==============================] - 34s 46ms/step - loss: 2.9258 - accuracy: 0.5615 - val_loss: 4.7419 - val_accuracy: 0.3274\n",
      "Epoch 69/170\n",
      "748/748 [==============================] - 34s 46ms/step - loss: 2.9019 - accuracy: 0.5653 - val_loss: 4.7394 - val_accuracy: 0.3258\n",
      "Epoch 70/170\n",
      "747/748 [============================>.] - ETA: 0s - loss: 2.8712 - accuracy: 0.5706\n",
      "Epoch 00070: saving model to /home/jupyter/workspace/Documents/music-generator/research/models/shfull-generator-70-2.8708229064941406\n",
      "INFO:tensorflow:Assets written to: /home/jupyter/workspace/Documents/music-generator/research/models/shfull-generator-70-2.8708229064941406/assets\n",
      "748/748 [==============================] - 49s 66ms/step - loss: 2.8708 - accuracy: 0.5707 - val_loss: 4.7348 - val_accuracy: 0.3308\n",
      "Epoch 71/170\n",
      "748/748 [==============================] - 34s 46ms/step - loss: 2.8629 - accuracy: 0.5746 - val_loss: 4.7682 - val_accuracy: 0.3242\n",
      "Epoch 72/170\n",
      "748/748 [==============================] - 34s 46ms/step - loss: 2.8291 - accuracy: 0.5833 - val_loss: 4.7289 - val_accuracy: 0.3321\n",
      "Epoch 73/170\n",
      "748/748 [==============================] - 34s 46ms/step - loss: 2.8160 - accuracy: 0.5828 - val_loss: 4.7931 - val_accuracy: 0.3287\n",
      "Epoch 74/170\n",
      "748/748 [==============================] - 34s 46ms/step - loss: 2.8027 - accuracy: 0.5867 - val_loss: 4.7273 - val_accuracy: 0.3393\n",
      "Epoch 75/170\n",
      "748/748 [==============================] - 34s 46ms/step - loss: 2.7799 - accuracy: 0.5896 - val_loss: 4.7126 - val_accuracy: 0.3427\n",
      "Epoch 76/170\n",
      "748/748 [==============================] - 34s 46ms/step - loss: 2.7588 - accuracy: 0.5952 - val_loss: 4.7253 - val_accuracy: 0.3417\n",
      "Epoch 77/170\n",
      "748/748 [==============================] - 34s 46ms/step - loss: 2.7416 - accuracy: 0.5984 - val_loss: 4.7176 - val_accuracy: 0.3415\n",
      "Epoch 78/170\n",
      "748/748 [==============================] - 34s 46ms/step - loss: 2.7287 - accuracy: 0.6018 - val_loss: 4.7567 - val_accuracy: 0.3337\n",
      "Epoch 79/170\n",
      "748/748 [==============================] - 34s 46ms/step - loss: 2.7127 - accuracy: 0.6027 - val_loss: 4.7220 - val_accuracy: 0.3421\n",
      "Epoch 80/170\n",
      "747/748 [============================>.] - ETA: 0s - loss: 2.6906 - accuracy: 0.6062\n",
      "Epoch 00080: saving model to /home/jupyter/workspace/Documents/music-generator/research/models/shfull-generator-80-2.6907827854156494\n",
      "INFO:tensorflow:Assets written to: /home/jupyter/workspace/Documents/music-generator/research/models/shfull-generator-80-2.6907827854156494/assets\n",
      "748/748 [==============================] - 49s 66ms/step - loss: 2.6908 - accuracy: 0.6062 - val_loss: 4.7238 - val_accuracy: 0.3458\n",
      "Epoch 81/170\n",
      "748/748 [==============================] - 34s 46ms/step - loss: 2.6569 - accuracy: 0.6140 - val_loss: 4.7725 - val_accuracy: 0.3381\n",
      "Epoch 82/170\n",
      "748/748 [==============================] - 34s 46ms/step - loss: 2.6539 - accuracy: 0.6167 - val_loss: 4.7461 - val_accuracy: 0.3368\n",
      "Epoch 83/170\n",
      "748/748 [==============================] - 34s 46ms/step - loss: 2.6189 - accuracy: 0.6238 - val_loss: 4.6825 - val_accuracy: 0.3502\n",
      "Epoch 84/170\n",
      "748/748 [==============================] - 34s 46ms/step - loss: 2.6096 - accuracy: 0.6244 - val_loss: 4.6824 - val_accuracy: 0.3500\n",
      "Epoch 85/170\n",
      "748/748 [==============================] - 34s 46ms/step - loss: 2.5899 - accuracy: 0.6252 - val_loss: 4.7205 - val_accuracy: 0.3462\n",
      "Epoch 86/170\n",
      "748/748 [==============================] - 34s 46ms/step - loss: 2.5780 - accuracy: 0.6317 - val_loss: 4.7061 - val_accuracy: 0.3516\n",
      "Epoch 87/170\n",
      "748/748 [==============================] - 34s 46ms/step - loss: 2.5516 - accuracy: 0.6325 - val_loss: 4.7129 - val_accuracy: 0.3528\n",
      "Epoch 88/170\n",
      "748/748 [==============================] - 34s 46ms/step - loss: 2.5346 - accuracy: 0.6367 - val_loss: 4.7154 - val_accuracy: 0.3496\n",
      "Epoch 89/170\n",
      "748/748 [==============================] - 34s 46ms/step - loss: 2.5322 - accuracy: 0.6392 - val_loss: 4.8194 - val_accuracy: 0.3303\n",
      "Epoch 90/170\n",
      "747/748 [============================>.] - ETA: 0s - loss: 2.5223 - accuracy: 0.6384\n",
      "Epoch 00090: saving model to /home/jupyter/workspace/Documents/music-generator/research/models/shfull-generator-90-2.522768497467041\n",
      "INFO:tensorflow:Assets written to: /home/jupyter/workspace/Documents/music-generator/research/models/shfull-generator-90-2.522768497467041/assets\n",
      "748/748 [==============================] - 49s 66ms/step - loss: 2.5228 - accuracy: 0.6382 - val_loss: 4.7029 - val_accuracy: 0.3540\n",
      "Epoch 91/170\n",
      "748/748 [==============================] - 34s 46ms/step - loss: 2.4970 - accuracy: 0.6436 - val_loss: 4.7638 - val_accuracy: 0.3534\n",
      "Epoch 92/170\n",
      "748/748 [==============================] - 34s 46ms/step - loss: 2.4686 - accuracy: 0.6496 - val_loss: 4.6789 - val_accuracy: 0.3586\n",
      "Epoch 93/170\n",
      "748/748 [==============================] - 34s 46ms/step - loss: 2.4592 - accuracy: 0.6502 - val_loss: 4.7066 - val_accuracy: 0.3599\n",
      "Epoch 94/170\n",
      "748/748 [==============================] - 34s 46ms/step - loss: 2.4756 - accuracy: 0.6492 - val_loss: 4.6914 - val_accuracy: 0.3619\n",
      "Epoch 95/170\n",
      "748/748 [==============================] - 34s 46ms/step - loss: 2.4627 - accuracy: 0.6498 - val_loss: 4.7572 - val_accuracy: 0.3514\n",
      "Epoch 96/170\n",
      "748/748 [==============================] - 34s 46ms/step - loss: 2.4368 - accuracy: 0.6542 - val_loss: 4.7419 - val_accuracy: 0.3595\n",
      "Epoch 97/170\n",
      "748/748 [==============================] - 34s 46ms/step - loss: 2.4158 - accuracy: 0.6566 - val_loss: 4.7336 - val_accuracy: 0.3544\n",
      "Epoch 98/170\n",
      "748/748 [==============================] - 34s 46ms/step - loss: 2.4108 - accuracy: 0.6594 - val_loss: 4.7308 - val_accuracy: 0.3511\n",
      "Epoch 99/170\n",
      "748/748 [==============================] - 34s 46ms/step - loss: 2.3984 - accuracy: 0.6599 - val_loss: 4.7562 - val_accuracy: 0.3591\n",
      "Epoch 100/170\n",
      "747/748 [============================>.] - ETA: 0s - loss: 2.4078 - accuracy: 0.6606\n",
      "Epoch 00100: saving model to /home/jupyter/workspace/Documents/music-generator/research/models/shfull-generator-100-2.407496213912964\n",
      "INFO:tensorflow:Assets written to: /home/jupyter/workspace/Documents/music-generator/research/models/shfull-generator-100-2.407496213912964/assets\n",
      "748/748 [==============================] - 49s 65ms/step - loss: 2.4075 - accuracy: 0.6607 - val_loss: 4.7014 - val_accuracy: 0.3575\n",
      "Epoch 101/170\n",
      "748/748 [==============================] - 34s 46ms/step - loss: 2.3850 - accuracy: 0.6645 - val_loss: 4.6831 - val_accuracy: 0.3670\n",
      "Epoch 102/170\n",
      "748/748 [==============================] - 34s 46ms/step - loss: 2.3655 - accuracy: 0.6683 - val_loss: 4.7661 - val_accuracy: 0.3618\n",
      "Epoch 103/170\n",
      "748/748 [==============================] - 34s 46ms/step - loss: 2.3721 - accuracy: 0.6664 - val_loss: 4.7332 - val_accuracy: 0.3698\n",
      "Epoch 104/170\n",
      "748/748 [==============================] - 34s 46ms/step - loss: 2.3568 - accuracy: 0.6710 - val_loss: 4.7656 - val_accuracy: 0.3599\n",
      "Epoch 105/170\n",
      "748/748 [==============================] - 34s 46ms/step - loss: 2.3533 - accuracy: 0.6728 - val_loss: 4.7364 - val_accuracy: 0.3675\n",
      "Epoch 106/170\n",
      "748/748 [==============================] - 34s 46ms/step - loss: 2.3321 - accuracy: 0.6746 - val_loss: 4.7383 - val_accuracy: 0.3718\n",
      "Epoch 107/170\n",
      "748/748 [==============================] - 34s 46ms/step - loss: 2.3213 - accuracy: 0.6758 - val_loss: 4.7411 - val_accuracy: 0.3612\n",
      "Epoch 108/170\n",
      "748/748 [==============================] - 34s 46ms/step - loss: 2.3106 - accuracy: 0.6784 - val_loss: 4.7493 - val_accuracy: 0.3679\n",
      "Epoch 109/170\n",
      "748/748 [==============================] - 34s 46ms/step - loss: 2.2892 - accuracy: 0.6839 - val_loss: 4.7182 - val_accuracy: 0.3713\n",
      "Epoch 110/170\n",
      "747/748 [============================>.] - ETA: 0s - loss: 2.2915 - accuracy: 0.6821\n",
      "Epoch 00110: saving model to /home/jupyter/workspace/Documents/music-generator/research/models/shfull-generator-110-2.291163206100464\n",
      "INFO:tensorflow:Assets written to: /home/jupyter/workspace/Documents/music-generator/research/models/shfull-generator-110-2.291163206100464/assets\n",
      "748/748 [==============================] - 49s 66ms/step - loss: 2.2912 - accuracy: 0.6821 - val_loss: 4.7683 - val_accuracy: 0.3654\n",
      "Epoch 111/170\n",
      "748/748 [==============================] - 34s 46ms/step - loss: 2.2881 - accuracy: 0.6832 - val_loss: 4.8279 - val_accuracy: 0.3494\n",
      "Epoch 112/170\n",
      "748/748 [==============================] - 34s 46ms/step - loss: 2.2973 - accuracy: 0.6820 - val_loss: 4.7532 - val_accuracy: 0.3679\n",
      "Epoch 113/170\n",
      "748/748 [==============================] - 34s 46ms/step - loss: 2.2643 - accuracy: 0.6879 - val_loss: 4.7370 - val_accuracy: 0.3736\n",
      "Epoch 114/170\n",
      "748/748 [==============================] - 34s 46ms/step - loss: 2.2690 - accuracy: 0.6876 - val_loss: 4.7226 - val_accuracy: 0.3750\n",
      "Epoch 115/170\n",
      "748/748 [==============================] - 34s 46ms/step - loss: 2.2587 - accuracy: 0.6890 - val_loss: 4.7910 - val_accuracy: 0.3620\n",
      "Epoch 116/170\n",
      "748/748 [==============================] - 34s 46ms/step - loss: 2.2677 - accuracy: 0.6899 - val_loss: 4.7530 - val_accuracy: 0.3689\n",
      "Epoch 117/170\n",
      "748/748 [==============================] - 34s 46ms/step - loss: 2.2484 - accuracy: 0.6928 - val_loss: 4.7832 - val_accuracy: 0.3699\n",
      "Epoch 118/170\n",
      "748/748 [==============================] - 34s 46ms/step - loss: 2.2420 - accuracy: 0.6922 - val_loss: 4.7850 - val_accuracy: 0.3657\n",
      "Epoch 119/170\n",
      "748/748 [==============================] - 34s 46ms/step - loss: 2.2384 - accuracy: 0.6933 - val_loss: 4.7685 - val_accuracy: 0.3734\n",
      "Epoch 120/170\n",
      "747/748 [============================>.] - ETA: 0s - loss: 2.2250 - accuracy: 0.6953\n",
      "Epoch 00120: saving model to /home/jupyter/workspace/Documents/music-generator/research/models/shfull-generator-120-2.2247469425201416\n",
      "INFO:tensorflow:Assets written to: /home/jupyter/workspace/Documents/music-generator/research/models/shfull-generator-120-2.2247469425201416/assets\n",
      "748/748 [==============================] - 49s 66ms/step - loss: 2.2247 - accuracy: 0.6952 - val_loss: 4.7654 - val_accuracy: 0.3708\n",
      "Epoch 121/170\n",
      "748/748 [==============================] - 34s 46ms/step - loss: 2.2180 - accuracy: 0.6950 - val_loss: 4.8209 - val_accuracy: 0.3589\n",
      "Epoch 122/170\n",
      "748/748 [==============================] - 34s 46ms/step - loss: 2.2108 - accuracy: 0.6974 - val_loss: 4.7624 - val_accuracy: 0.3754\n",
      "Epoch 123/170\n",
      "748/748 [==============================] - 34s 46ms/step - loss: 2.1890 - accuracy: 0.7027 - val_loss: 4.7788 - val_accuracy: 0.3729\n",
      "Epoch 124/170\n",
      "748/748 [==============================] - 34s 46ms/step - loss: 2.1963 - accuracy: 0.7026 - val_loss: 4.8012 - val_accuracy: 0.3686\n",
      "Epoch 125/170\n",
      "748/748 [==============================] - 34s 46ms/step - loss: 2.2024 - accuracy: 0.6999 - val_loss: 4.7590 - val_accuracy: 0.3691\n",
      "Epoch 126/170\n",
      "748/748 [==============================] - 34s 46ms/step - loss: 2.1878 - accuracy: 0.7013 - val_loss: 4.8266 - val_accuracy: 0.3688\n",
      "Epoch 127/170\n",
      "748/748 [==============================] - 34s 46ms/step - loss: 2.1824 - accuracy: 0.7026 - val_loss: 4.7539 - val_accuracy: 0.3762\n",
      "Epoch 128/170\n",
      "748/748 [==============================] - 34s 46ms/step - loss: 2.1736 - accuracy: 0.7043 - val_loss: 4.7642 - val_accuracy: 0.3761\n",
      "Epoch 129/170\n",
      "748/748 [==============================] - 34s 46ms/step - loss: 2.1696 - accuracy: 0.7033 - val_loss: 4.7937 - val_accuracy: 0.3743\n",
      "Epoch 130/170\n",
      "747/748 [============================>.] - ETA: 0s - loss: 2.1647 - accuracy: 0.7045\n",
      "Epoch 00130: saving model to /home/jupyter/workspace/Documents/music-generator/research/models/shfull-generator-130-2.1643128395080566\n",
      "INFO:tensorflow:Assets written to: /home/jupyter/workspace/Documents/music-generator/research/models/shfull-generator-130-2.1643128395080566/assets\n",
      "748/748 [==============================] - 49s 66ms/step - loss: 2.1643 - accuracy: 0.7045 - val_loss: 4.8078 - val_accuracy: 0.3721\n",
      "Epoch 131/170\n",
      "748/748 [==============================] - 34s 46ms/step - loss: 2.1647 - accuracy: 0.7028 - val_loss: 4.7996 - val_accuracy: 0.3723\n",
      "Epoch 132/170\n",
      "748/748 [==============================] - 34s 46ms/step - loss: 2.1581 - accuracy: 0.7067 - val_loss: 4.9766 - val_accuracy: 0.3480\n",
      "Epoch 133/170\n",
      "748/748 [==============================] - 34s 46ms/step - loss: 2.1633 - accuracy: 0.7059 - val_loss: 4.7900 - val_accuracy: 0.3776\n",
      "Epoch 134/170\n",
      "748/748 [==============================] - 34s 46ms/step - loss: 2.1543 - accuracy: 0.7064 - val_loss: 4.7805 - val_accuracy: 0.3785\n",
      "Epoch 135/170\n",
      "748/748 [==============================] - 34s 46ms/step - loss: 2.1433 - accuracy: 0.7082 - val_loss: 4.8299 - val_accuracy: 0.3735\n",
      "Epoch 136/170\n",
      "748/748 [==============================] - 34s 46ms/step - loss: 2.1566 - accuracy: 0.7076 - val_loss: 4.7967 - val_accuracy: 0.3763\n",
      "Epoch 137/170\n",
      "748/748 [==============================] - 34s 46ms/step - loss: 2.1368 - accuracy: 0.7080 - val_loss: 4.8514 - val_accuracy: 0.3661\n",
      "Epoch 138/170\n",
      "748/748 [==============================] - 34s 46ms/step - loss: 2.1472 - accuracy: 0.7068 - val_loss: 4.7855 - val_accuracy: 0.3763\n",
      "Epoch 139/170\n",
      "748/748 [==============================] - 34s 46ms/step - loss: 2.1367 - accuracy: 0.7077 - val_loss: 4.8405 - val_accuracy: 0.3718\n",
      "Epoch 140/170\n",
      "747/748 [============================>.] - ETA: 0s - loss: 2.1263 - accuracy: 0.7107\n",
      "Epoch 00140: saving model to /home/jupyter/workspace/Documents/music-generator/research/models/shfull-generator-140-2.126072645187378\n",
      "INFO:tensorflow:Assets written to: /home/jupyter/workspace/Documents/music-generator/research/models/shfull-generator-140-2.126072645187378/assets\n",
      "748/748 [==============================] - 49s 66ms/step - loss: 2.1261 - accuracy: 0.7107 - val_loss: 4.8494 - val_accuracy: 0.3805\n",
      "Epoch 141/170\n",
      "748/748 [==============================] - 34s 46ms/step - loss: 2.1215 - accuracy: 0.7135 - val_loss: 4.8618 - val_accuracy: 0.3743\n",
      "Epoch 142/170\n",
      "748/748 [==============================] - 35s 46ms/step - loss: 2.1074 - accuracy: 0.7150 - val_loss: 4.8119 - val_accuracy: 0.3811\n",
      "Epoch 143/170\n",
      "748/748 [==============================] - 34s 46ms/step - loss: 2.1200 - accuracy: 0.7118 - val_loss: 4.8090 - val_accuracy: 0.3784\n",
      "Epoch 144/170\n",
      "748/748 [==============================] - 34s 46ms/step - loss: 2.1253 - accuracy: 0.7092 - val_loss: 4.8844 - val_accuracy: 0.3682\n",
      "Epoch 145/170\n",
      "748/748 [==============================] - 34s 46ms/step - loss: 2.1185 - accuracy: 0.7116 - val_loss: 4.8429 - val_accuracy: 0.3725\n",
      "Epoch 146/170\n",
      "748/748 [==============================] - 34s 46ms/step - loss: 2.1214 - accuracy: 0.7110 - val_loss: 4.8418 - val_accuracy: 0.3741\n",
      "Epoch 147/170\n",
      "748/748 [==============================] - 34s 46ms/step - loss: 2.0983 - accuracy: 0.7128 - val_loss: 4.8566 - val_accuracy: 0.3820\n",
      "Epoch 148/170\n",
      "748/748 [==============================] - 34s 46ms/step - loss: 2.1045 - accuracy: 0.7145 - val_loss: 4.8045 - val_accuracy: 0.3775\n",
      "Epoch 149/170\n",
      "748/748 [==============================] - 34s 46ms/step - loss: 2.1057 - accuracy: 0.7128 - val_loss: 4.8109 - val_accuracy: 0.3802\n",
      "Epoch 150/170\n",
      "747/748 [============================>.] - ETA: 0s - loss: 2.1083 - accuracy: 0.7128\n",
      "Epoch 00150: saving model to /home/jupyter/workspace/Documents/music-generator/research/models/shfull-generator-150-2.1075680255889893\n",
      "INFO:tensorflow:Assets written to: /home/jupyter/workspace/Documents/music-generator/research/models/shfull-generator-150-2.1075680255889893/assets\n",
      "748/748 [==============================] - 49s 65ms/step - loss: 2.1076 - accuracy: 0.7129 - val_loss: 4.8386 - val_accuracy: 0.3788\n",
      "Epoch 151/170\n",
      "748/748 [==============================] - 34s 46ms/step - loss: 2.1121 - accuracy: 0.7113 - val_loss: 4.8460 - val_accuracy: 0.3758\n",
      "Epoch 152/170\n",
      "748/748 [==============================] - 34s 46ms/step - loss: 2.1015 - accuracy: 0.7135 - val_loss: 4.8261 - val_accuracy: 0.3815\n",
      "Epoch 153/170\n",
      "748/748 [==============================] - 34s 46ms/step - loss: 2.1106 - accuracy: 0.7108 - val_loss: 4.8165 - val_accuracy: 0.3805\n",
      "Epoch 154/170\n",
      "748/748 [==============================] - 34s 46ms/step - loss: 2.1041 - accuracy: 0.7157 - val_loss: 4.8711 - val_accuracy: 0.3759\n",
      "Epoch 155/170\n",
      "748/748 [==============================] - 34s 46ms/step - loss: 2.1086 - accuracy: 0.7104 - val_loss: 4.8577 - val_accuracy: 0.3719\n",
      "Epoch 156/170\n",
      "748/748 [==============================] - 34s 46ms/step - loss: 2.0932 - accuracy: 0.7172 - val_loss: 4.8896 - val_accuracy: 0.3794\n",
      "Epoch 157/170\n",
      "748/748 [==============================] - 34s 46ms/step - loss: 2.0911 - accuracy: 0.7149 - val_loss: 4.8629 - val_accuracy: 0.3753\n",
      "Epoch 158/170\n",
      "748/748 [==============================] - 34s 46ms/step - loss: 2.0947 - accuracy: 0.7162 - val_loss: 4.8701 - val_accuracy: 0.3772\n",
      "Epoch 159/170\n",
      "748/748 [==============================] - 34s 46ms/step - loss: 2.0990 - accuracy: 0.7111 - val_loss: 4.8553 - val_accuracy: 0.3746\n",
      "Epoch 160/170\n",
      "747/748 [============================>.] - ETA: 0s - loss: 2.0929 - accuracy: 0.7143\n",
      "Epoch 00160: saving model to /home/jupyter/workspace/Documents/music-generator/research/models/shfull-generator-160-2.0936179161071777\n",
      "INFO:tensorflow:Assets written to: /home/jupyter/workspace/Documents/music-generator/research/models/shfull-generator-160-2.0936179161071777/assets\n",
      "748/748 [==============================] - 49s 66ms/step - loss: 2.0936 - accuracy: 0.7142 - val_loss: 4.8717 - val_accuracy: 0.3754\n",
      "Epoch 161/170\n",
      "748/748 [==============================] - 34s 46ms/step - loss: 2.0884 - accuracy: 0.7161 - val_loss: 4.8822 - val_accuracy: 0.3745\n",
      "Epoch 162/170\n",
      "748/748 [==============================] - 34s 46ms/step - loss: 2.0987 - accuracy: 0.7134 - val_loss: 4.9309 - val_accuracy: 0.3745\n",
      "Epoch 163/170\n",
      "748/748 [==============================] - 34s 46ms/step - loss: 2.1226 - accuracy: 0.7074 - val_loss: 4.9273 - val_accuracy: 0.3696\n",
      "Epoch 164/170\n",
      "748/748 [==============================] - 34s 46ms/step - loss: 2.1360 - accuracy: 0.7061 - val_loss: 4.8911 - val_accuracy: 0.3797\n",
      "Epoch 165/170\n",
      "748/748 [==============================] - 34s 46ms/step - loss: 2.1253 - accuracy: 0.7086 - val_loss: 4.8963 - val_accuracy: 0.3782\n",
      "Epoch 166/170\n",
      "748/748 [==============================] - 34s 46ms/step - loss: 2.1416 - accuracy: 0.7043 - val_loss: 4.8729 - val_accuracy: 0.3767\n",
      "Epoch 167/170\n",
      "748/748 [==============================] - 34s 46ms/step - loss: 2.1554 - accuracy: 0.7030 - val_loss: 4.9095 - val_accuracy: 0.3718\n",
      "Epoch 168/170\n",
      "748/748 [==============================] - 34s 46ms/step - loss: 2.1603 - accuracy: 0.6997 - val_loss: 4.8890 - val_accuracy: 0.3755\n",
      "Epoch 169/170\n",
      "748/748 [==============================] - 34s 46ms/step - loss: 2.1600 - accuracy: 0.7009 - val_loss: 4.9260 - val_accuracy: 0.3734\n",
      "Epoch 170/170\n",
      "747/748 [============================>.] - ETA: 0s - loss: 2.1959 - accuracy: 0.6924\n",
      "Epoch 00170: saving model to /home/jupyter/workspace/Documents/music-generator/research/models/shfull-generator-170-2.1957473754882812\n",
      "INFO:tensorflow:Assets written to: /home/jupyter/workspace/Documents/music-generator/research/models/shfull-generator-170-2.1957473754882812/assets\n",
      "748/748 [==============================] - 49s 66ms/step - loss: 2.1957 - accuracy: 0.6924 - val_loss: 4.9648 - val_accuracy: 0.3623\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f88d8200748>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "config = tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "sh_generator: ChordGeneratorMusicModel = ChordGeneratorMusicModel(generator_seq_len, len(tokenizer.word_index) + 1)\n",
    "checkpoint: ModelCheckpoint = ModelCheckpoint(\n",
    "    os.path.abspath(\"./models/shfull-generator-{epoch}-{loss}\"),\n",
    "    period=10,\n",
    "    monitor='loss',\n",
    "    verbose=1,\n",
    "    save_best_only=False,\n",
    "    mode='min'\n",
    ")\n",
    "sh_generator.fit(train_x, train_y, epochs=170, batch_size=64, callbacks=[checkpoint], validation_data=(test_x, test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./models/shfull-scaler.pckl\", \"wb\") as f:\n",
    "    pickle.dump(scaler, f)\n",
    "with open(\"./models/shfull-tokenizer.pckl\", \"wb\") as f:\n",
    "    pickle.dump(tokenizer, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbChordGeneratorMusicModel:\n",
    "    def __init__(self, seq_len: int, chords_vocab_size: int):\n",
    "        random.set_seed(RANDOM_STATE)\n",
    "        chords_input = Input(shape=seq_len)\n",
    "        embedding = Embedding(chords_vocab_size + 1, 100)(chords_input)\n",
    "        bilstm = Bidirectional(LSTM(512, return_sequences=True))(embedding)\n",
    "        attention = SeqSelfAttention(attention_activation=\"sigmoid\")(bilstm)\n",
    "        dropout = Dropout(0.3)(attention)\n",
    "        lstm = LSTM(1024, return_sequences=True)(dropout)\n",
    "        dropout = Dropout(0.3)(lstm)\n",
    "        lstm = LSTM(512, return_sequences=True)(dropout)\n",
    "        pool = GlobalAveragePooling1D()(lstm)\n",
    "        dense = Dense(512)(pool)\n",
    "        chord_output = Dense(chords_vocab_size + 1, activation=\"softmax\")(dense)\n",
    "        self._model = Model(chords_input, chord_output)\n",
    "        self._model.compile(loss='sparse_categorical_crossentropy', optimizer='rmsprop', metrics=[\"accuracy\"])\n",
    "\n",
    "    def fit(self, train_x, train_y, **kwargs):\n",
    "        return self._model.fit(train_x, train_y, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = samples[\"ChordDurationSeq\"]\n",
    "Y = samples[\"NextChordDuration\"]\n",
    "\n",
    "tokenizer: Tokenizer = Tokenizer(filters=\"\")\n",
    "tokenizer.fit_on_texts(X)\n",
    "tokenizer.fit_on_texts(Y)\n",
    "\n",
    "X = np.array([z for sublist in tokenizer.texts_to_sequences(X) for z in sublist]).reshape((-1, generator_seq_len))\n",
    "Y = np.array([z for sublist in tokenizer.texts_to_sequences(Y) for z in sublist])\n",
    "train_x, test_x, train_y, test_y = train_test_split(X, Y, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/170\n",
      "748/748 [==============================] - 68s 91ms/step - loss: 6.3505 - accuracy: 0.0236 - val_loss: 6.1622 - val_accuracy: 0.0274\n",
      "Epoch 2/170\n",
      "748/748 [==============================] - 67s 90ms/step - loss: 6.1141 - accuracy: 0.0308 - val_loss: 6.0669 - val_accuracy: 0.0362\n",
      "Epoch 3/170\n",
      "748/748 [==============================] - 68s 90ms/step - loss: 5.9354 - accuracy: 0.0417 - val_loss: 5.9450 - val_accuracy: 0.0494\n",
      "Epoch 4/170\n",
      "748/748 [==============================] - 68s 91ms/step - loss: 5.7152 - accuracy: 0.0581 - val_loss: 5.6551 - val_accuracy: 0.0652\n",
      "Epoch 5/170\n",
      "748/748 [==============================] - 68s 91ms/step - loss: 5.5044 - accuracy: 0.0741 - val_loss: 5.5071 - val_accuracy: 0.0790\n",
      "Epoch 6/170\n",
      "748/748 [==============================] - 68s 91ms/step - loss: 5.3034 - accuracy: 0.0919 - val_loss: 5.4010 - val_accuracy: 0.0863\n",
      "Epoch 7/170\n",
      "748/748 [==============================] - 68s 91ms/step - loss: 5.1241 - accuracy: 0.1110 - val_loss: 5.2591 - val_accuracy: 0.1011\n",
      "Epoch 8/170\n",
      "748/748 [==============================] - 68s 91ms/step - loss: 4.9523 - accuracy: 0.1267 - val_loss: 5.0283 - val_accuracy: 0.1280\n",
      "Epoch 9/170\n",
      "748/748 [==============================] - 68s 91ms/step - loss: 4.7970 - accuracy: 0.1459 - val_loss: 4.9199 - val_accuracy: 0.1491\n",
      "Epoch 10/170\n",
      "748/748 [==============================] - ETA: 0s - loss: 4.6316 - accuracy: 0.1646\n",
      "Epoch 00010: saving model to /home/jupyter/workspace/Documents/music-generator/research/models/emb-generator-10-4.631646156311035\n",
      "INFO:tensorflow:Assets written to: /home/jupyter/workspace/Documents/music-generator/research/models/emb-generator-10-4.631646156311035/assets\n",
      "748/748 [==============================] - 87s 116ms/step - loss: 4.6316 - accuracy: 0.1646 - val_loss: 4.7655 - val_accuracy: 0.1649\n",
      "Epoch 11/170\n",
      "748/748 [==============================] - 68s 91ms/step - loss: 4.5152 - accuracy: 0.1816 - val_loss: 4.7394 - val_accuracy: 0.1709\n",
      "Epoch 12/170\n",
      "748/748 [==============================] - 68s 91ms/step - loss: 4.4631 - accuracy: 0.2015 - val_loss: 4.7405 - val_accuracy: 0.1890\n",
      "Epoch 13/170\n",
      "748/748 [==============================] - 68s 91ms/step - loss: 4.4301 - accuracy: 0.2163 - val_loss: 4.7778 - val_accuracy: 0.1975\n",
      "Epoch 14/170\n",
      "748/748 [==============================] - 68s 91ms/step - loss: 4.3460 - accuracy: 0.2355 - val_loss: 4.7456 - val_accuracy: 0.2096\n",
      "Epoch 15/170\n",
      "748/748 [==============================] - 68s 91ms/step - loss: 4.2614 - accuracy: 0.2534 - val_loss: 4.7252 - val_accuracy: 0.2221\n",
      "Epoch 16/170\n",
      "748/748 [==============================] - 68s 91ms/step - loss: 4.1692 - accuracy: 0.2718 - val_loss: 4.6391 - val_accuracy: 0.2428\n",
      "Epoch 17/170\n",
      "748/748 [==============================] - 68s 91ms/step - loss: 4.0683 - accuracy: 0.2934 - val_loss: 4.6070 - val_accuracy: 0.2542\n",
      "Epoch 18/170\n",
      "748/748 [==============================] - 68s 91ms/step - loss: 3.9920 - accuracy: 0.3094 - val_loss: 4.5612 - val_accuracy: 0.2673\n",
      "Epoch 19/170\n",
      "748/748 [==============================] - 68s 91ms/step - loss: 3.9066 - accuracy: 0.3289 - val_loss: 4.5316 - val_accuracy: 0.2748\n",
      "Epoch 20/170\n",
      "748/748 [==============================] - ETA: 0s - loss: 3.8195 - accuracy: 0.3459\n",
      "Epoch 00020: saving model to /home/jupyter/workspace/Documents/music-generator/research/models/emb-generator-20-3.8195383548736572\n",
      "INFO:tensorflow:Assets written to: /home/jupyter/workspace/Documents/music-generator/research/models/emb-generator-20-3.8195383548736572/assets\n",
      "748/748 [==============================] - 87s 116ms/step - loss: 3.8195 - accuracy: 0.3459 - val_loss: 4.5608 - val_accuracy: 0.2777\n",
      "Epoch 21/170\n",
      "748/748 [==============================] - 68s 91ms/step - loss: 3.7443 - accuracy: 0.3640 - val_loss: 4.4587 - val_accuracy: 0.2944\n",
      "Epoch 22/170\n",
      "748/748 [==============================] - 68s 91ms/step - loss: 3.6577 - accuracy: 0.3805 - val_loss: 4.4990 - val_accuracy: 0.3025\n",
      "Epoch 23/170\n",
      "748/748 [==============================] - 68s 91ms/step - loss: 3.6126 - accuracy: 0.3930 - val_loss: 4.4027 - val_accuracy: 0.3178\n",
      "Epoch 24/170\n",
      "748/748 [==============================] - 68s 91ms/step - loss: 3.5451 - accuracy: 0.4098 - val_loss: 4.4388 - val_accuracy: 0.3222\n",
      "Epoch 25/170\n",
      "748/748 [==============================] - 68s 91ms/step - loss: 3.4771 - accuracy: 0.4235 - val_loss: 4.4275 - val_accuracy: 0.3286\n",
      "Epoch 26/170\n",
      "748/748 [==============================] - 68s 91ms/step - loss: 3.4134 - accuracy: 0.4364 - val_loss: 4.4057 - val_accuracy: 0.3361\n",
      "Epoch 27/170\n",
      "748/748 [==============================] - 68s 91ms/step - loss: 3.3613 - accuracy: 0.4454 - val_loss: 4.3955 - val_accuracy: 0.3410\n",
      "Epoch 28/170\n",
      "748/748 [==============================] - 68s 91ms/step - loss: 3.2998 - accuracy: 0.4592 - val_loss: 4.3513 - val_accuracy: 0.3576\n",
      "Epoch 29/170\n",
      "748/748 [==============================] - 68s 91ms/step - loss: 3.2377 - accuracy: 0.4737 - val_loss: 4.3515 - val_accuracy: 0.3601\n",
      "Epoch 30/170\n",
      "748/748 [==============================] - ETA: 0s - loss: 3.1939 - accuracy: 0.4815\n",
      "Epoch 00030: saving model to /home/jupyter/workspace/Documents/music-generator/research/models/emb-generator-30-3.1938676834106445\n",
      "INFO:tensorflow:Assets written to: /home/jupyter/workspace/Documents/music-generator/research/models/emb-generator-30-3.1938676834106445/assets\n",
      "748/748 [==============================] - 86s 116ms/step - loss: 3.1939 - accuracy: 0.4815 - val_loss: 4.3433 - val_accuracy: 0.3667\n",
      "Epoch 31/170\n",
      "748/748 [==============================] - 68s 91ms/step - loss: 3.1526 - accuracy: 0.4926 - val_loss: 4.3273 - val_accuracy: 0.3694\n",
      "Epoch 32/170\n",
      "748/748 [==============================] - 68s 91ms/step - loss: 3.0982 - accuracy: 0.5022 - val_loss: 4.3354 - val_accuracy: 0.3729\n",
      "Epoch 33/170\n",
      "748/748 [==============================] - 68s 91ms/step - loss: 3.0490 - accuracy: 0.5151 - val_loss: 4.3586 - val_accuracy: 0.3771\n",
      "Epoch 34/170\n",
      "748/748 [==============================] - 68s 91ms/step - loss: 3.0284 - accuracy: 0.5197 - val_loss: 4.3347 - val_accuracy: 0.3798\n",
      "Epoch 35/170\n",
      "748/748 [==============================] - 68s 91ms/step - loss: 2.9749 - accuracy: 0.5304 - val_loss: 4.3379 - val_accuracy: 0.3824\n",
      "Epoch 36/170\n",
      "748/748 [==============================] - 68s 91ms/step - loss: 2.9457 - accuracy: 0.5347 - val_loss: 4.3152 - val_accuracy: 0.3938\n",
      "Epoch 37/170\n",
      "748/748 [==============================] - 68s 91ms/step - loss: 2.9161 - accuracy: 0.5410 - val_loss: 4.3132 - val_accuracy: 0.3950\n",
      "Epoch 38/170\n",
      "748/748 [==============================] - 68s 91ms/step - loss: 2.8794 - accuracy: 0.5491 - val_loss: 4.3282 - val_accuracy: 0.3963\n",
      "Epoch 39/170\n",
      "748/748 [==============================] - 68s 91ms/step - loss: 2.8419 - accuracy: 0.5545 - val_loss: 4.3502 - val_accuracy: 0.3953\n",
      "Epoch 40/170\n",
      "748/748 [==============================] - ETA: 0s - loss: 2.8114 - accuracy: 0.5610\n",
      "Epoch 00040: saving model to /home/jupyter/workspace/Documents/music-generator/research/models/emb-generator-40-2.811431884765625\n",
      "INFO:tensorflow:Assets written to: /home/jupyter/workspace/Documents/music-generator/research/models/emb-generator-40-2.811431884765625/assets\n",
      "748/748 [==============================] - 87s 116ms/step - loss: 2.8114 - accuracy: 0.5610 - val_loss: 4.2996 - val_accuracy: 0.3978\n",
      "Epoch 41/170\n",
      "748/748 [==============================] - 68s 91ms/step - loss: 2.7906 - accuracy: 0.5622 - val_loss: 4.3131 - val_accuracy: 0.4059\n",
      "Epoch 42/170\n",
      "748/748 [==============================] - 68s 91ms/step - loss: 2.7582 - accuracy: 0.5740 - val_loss: 4.3105 - val_accuracy: 0.4109\n",
      "Epoch 43/170\n",
      "748/748 [==============================] - 68s 91ms/step - loss: 2.7391 - accuracy: 0.5766 - val_loss: 4.3539 - val_accuracy: 0.4099\n",
      "Epoch 44/170\n",
      "748/748 [==============================] - 68s 91ms/step - loss: 2.7353 - accuracy: 0.5773 - val_loss: 4.3345 - val_accuracy: 0.4096\n",
      "Epoch 45/170\n",
      "748/748 [==============================] - 68s 91ms/step - loss: 2.7153 - accuracy: 0.5838 - val_loss: 4.3380 - val_accuracy: 0.4124\n",
      "Epoch 46/170\n",
      "748/748 [==============================] - 68s 91ms/step - loss: 2.6892 - accuracy: 0.5888 - val_loss: 4.3372 - val_accuracy: 0.4093\n",
      "Epoch 47/170\n",
      "748/748 [==============================] - 68s 91ms/step - loss: 2.6604 - accuracy: 0.5951 - val_loss: 4.2913 - val_accuracy: 0.4190\n",
      "Epoch 48/170\n",
      "748/748 [==============================] - 68s 91ms/step - loss: 2.6213 - accuracy: 0.5997 - val_loss: 4.3098 - val_accuracy: 0.4201\n",
      "Epoch 49/170\n",
      "748/748 [==============================] - 68s 91ms/step - loss: 2.6109 - accuracy: 0.6026 - val_loss: 4.3041 - val_accuracy: 0.4247\n",
      "Epoch 50/170\n",
      "748/748 [==============================] - ETA: 0s - loss: 2.5952 - accuracy: 0.6066\n",
      "Epoch 00050: saving model to /home/jupyter/workspace/Documents/music-generator/research/models/emb-generator-50-2.595174551010132\n",
      "INFO:tensorflow:Assets written to: /home/jupyter/workspace/Documents/music-generator/research/models/emb-generator-50-2.595174551010132/assets\n",
      "748/748 [==============================] - 87s 116ms/step - loss: 2.5952 - accuracy: 0.6066 - val_loss: 4.3331 - val_accuracy: 0.4218\n",
      "Epoch 51/170\n",
      "748/748 [==============================] - 68s 91ms/step - loss: 2.5768 - accuracy: 0.6105 - val_loss: 4.2919 - val_accuracy: 0.4285\n",
      "Epoch 52/170\n",
      "748/748 [==============================] - 68s 91ms/step - loss: 2.5637 - accuracy: 0.6129 - val_loss: 4.2933 - val_accuracy: 0.4222\n",
      "Epoch 53/170\n",
      "748/748 [==============================] - 68s 91ms/step - loss: 2.5481 - accuracy: 0.6155 - val_loss: 4.3130 - val_accuracy: 0.4278\n",
      "Epoch 54/170\n",
      "748/748 [==============================] - 68s 91ms/step - loss: 2.5495 - accuracy: 0.6166 - val_loss: 4.3531 - val_accuracy: 0.4224\n",
      "Epoch 55/170\n",
      "748/748 [==============================] - 68s 91ms/step - loss: 2.5179 - accuracy: 0.6247 - val_loss: 4.3364 - val_accuracy: 0.4285\n",
      "Epoch 56/170\n",
      "748/748 [==============================] - 68s 91ms/step - loss: 2.5149 - accuracy: 0.6274 - val_loss: 4.2970 - val_accuracy: 0.4305\n",
      "Epoch 57/170\n",
      "748/748 [==============================] - 68s 91ms/step - loss: 2.5012 - accuracy: 0.6279 - val_loss: 4.3643 - val_accuracy: 0.4255\n",
      "Epoch 58/170\n",
      "748/748 [==============================] - 68s 91ms/step - loss: 2.5000 - accuracy: 0.6290 - val_loss: 4.3399 - val_accuracy: 0.4310\n",
      "Epoch 59/170\n",
      "748/748 [==============================] - 68s 91ms/step - loss: 2.4881 - accuracy: 0.6297 - val_loss: 4.3163 - val_accuracy: 0.4348\n",
      "Epoch 60/170\n",
      "748/748 [==============================] - ETA: 0s - loss: 2.4655 - accuracy: 0.6341\n",
      "Epoch 00060: saving model to /home/jupyter/workspace/Documents/music-generator/research/models/emb-generator-60-2.4654934406280518\n",
      "INFO:tensorflow:Assets written to: /home/jupyter/workspace/Documents/music-generator/research/models/emb-generator-60-2.4654934406280518/assets\n",
      "748/748 [==============================] - 87s 116ms/step - loss: 2.4655 - accuracy: 0.6341 - val_loss: 4.3215 - val_accuracy: 0.4355\n",
      "Epoch 61/170\n",
      "748/748 [==============================] - 68s 91ms/step - loss: 2.4719 - accuracy: 0.6358 - val_loss: 4.3289 - val_accuracy: 0.4328\n",
      "Epoch 62/170\n",
      "748/748 [==============================] - 68s 91ms/step - loss: 2.4495 - accuracy: 0.6405 - val_loss: 4.3353 - val_accuracy: 0.4307\n",
      "Epoch 63/170\n",
      "748/748 [==============================] - 68s 91ms/step - loss: 2.4462 - accuracy: 0.6429 - val_loss: 4.3386 - val_accuracy: 0.4348\n",
      "Epoch 64/170\n",
      "748/748 [==============================] - 68s 91ms/step - loss: 2.4235 - accuracy: 0.6434 - val_loss: 4.3228 - val_accuracy: 0.4379\n",
      "Epoch 65/170\n",
      "748/748 [==============================] - 68s 91ms/step - loss: 2.4057 - accuracy: 0.6493 - val_loss: 4.3060 - val_accuracy: 0.4418\n",
      "Epoch 66/170\n",
      "748/748 [==============================] - 68s 91ms/step - loss: 2.3922 - accuracy: 0.6508 - val_loss: 4.3419 - val_accuracy: 0.4383\n",
      "Epoch 67/170\n",
      "748/748 [==============================] - 68s 91ms/step - loss: 2.3984 - accuracy: 0.6497 - val_loss: 4.3477 - val_accuracy: 0.4380\n",
      "Epoch 68/170\n",
      "748/748 [==============================] - 68s 91ms/step - loss: 2.3725 - accuracy: 0.6520 - val_loss: 4.3633 - val_accuracy: 0.4419\n",
      "Epoch 69/170\n",
      "748/748 [==============================] - 68s 91ms/step - loss: 2.3629 - accuracy: 0.6551 - val_loss: 4.3821 - val_accuracy: 0.4385\n",
      "Epoch 70/170\n",
      "748/748 [==============================] - ETA: 0s - loss: 2.3549 - accuracy: 0.6546\n",
      "Epoch 00070: saving model to /home/jupyter/workspace/Documents/music-generator/research/models/emb-generator-70-2.354889392852783\n",
      "INFO:tensorflow:Assets written to: /home/jupyter/workspace/Documents/music-generator/research/models/emb-generator-70-2.354889392852783/assets\n",
      "748/748 [==============================] - 87s 116ms/step - loss: 2.3549 - accuracy: 0.6546 - val_loss: 4.3610 - val_accuracy: 0.4439\n",
      "Epoch 71/170\n",
      "748/748 [==============================] - 68s 91ms/step - loss: 2.3494 - accuracy: 0.6572 - val_loss: 4.3949 - val_accuracy: 0.4434\n",
      "Epoch 72/170\n",
      "748/748 [==============================] - 68s 91ms/step - loss: 2.3443 - accuracy: 0.6588 - val_loss: 4.3679 - val_accuracy: 0.4418\n",
      "Epoch 73/170\n",
      "748/748 [==============================] - 68s 91ms/step - loss: 2.3308 - accuracy: 0.6610 - val_loss: 4.3441 - val_accuracy: 0.4463\n",
      "Epoch 74/170\n",
      "748/748 [==============================] - 68s 91ms/step - loss: 2.3159 - accuracy: 0.6619 - val_loss: 4.3908 - val_accuracy: 0.4410\n",
      "Epoch 75/170\n",
      "748/748 [==============================] - 68s 91ms/step - loss: 2.2989 - accuracy: 0.6656 - val_loss: 4.3700 - val_accuracy: 0.4422\n",
      "Epoch 76/170\n",
      "748/748 [==============================] - 68s 91ms/step - loss: 2.2943 - accuracy: 0.6676 - val_loss: 4.3986 - val_accuracy: 0.4401\n",
      "Epoch 77/170\n",
      "748/748 [==============================] - 68s 91ms/step - loss: 2.2802 - accuracy: 0.6679 - val_loss: 4.3954 - val_accuracy: 0.4428\n",
      "Epoch 78/170\n",
      "748/748 [==============================] - 68s 91ms/step - loss: 2.2816 - accuracy: 0.6711 - val_loss: 4.3794 - val_accuracy: 0.4455\n",
      "Epoch 79/170\n",
      "748/748 [==============================] - 68s 91ms/step - loss: 2.2697 - accuracy: 0.6693 - val_loss: 4.3958 - val_accuracy: 0.4471\n",
      "Epoch 80/170\n",
      "748/748 [==============================] - ETA: 0s - loss: 2.2675 - accuracy: 0.6699\n",
      "Epoch 00080: saving model to /home/jupyter/workspace/Documents/music-generator/research/models/emb-generator-80-2.2675089836120605\n",
      "INFO:tensorflow:Assets written to: /home/jupyter/workspace/Documents/music-generator/research/models/emb-generator-80-2.2675089836120605/assets\n",
      "748/748 [==============================] - 87s 116ms/step - loss: 2.2675 - accuracy: 0.6699 - val_loss: 4.3719 - val_accuracy: 0.4470\n",
      "Epoch 81/170\n",
      "748/748 [==============================] - 68s 91ms/step - loss: 2.2509 - accuracy: 0.6734 - val_loss: 4.3655 - val_accuracy: 0.4434\n",
      "Epoch 82/170\n",
      "748/748 [==============================] - 68s 91ms/step - loss: 2.2378 - accuracy: 0.6773 - val_loss: 4.3688 - val_accuracy: 0.4468\n",
      "Epoch 83/170\n",
      "748/748 [==============================] - 68s 91ms/step - loss: 2.2425 - accuracy: 0.6754 - val_loss: 4.3953 - val_accuracy: 0.4513\n",
      "Epoch 84/170\n",
      "748/748 [==============================] - 68s 91ms/step - loss: 2.2264 - accuracy: 0.6784 - val_loss: 4.3798 - val_accuracy: 0.4485\n",
      "Epoch 85/170\n",
      "748/748 [==============================] - 68s 91ms/step - loss: 2.2297 - accuracy: 0.6800 - val_loss: 4.3731 - val_accuracy: 0.4508\n",
      "Epoch 86/170\n",
      "748/748 [==============================] - 68s 91ms/step - loss: 2.2255 - accuracy: 0.6778 - val_loss: 4.3771 - val_accuracy: 0.4470\n",
      "Epoch 87/170\n",
      "748/748 [==============================] - 68s 91ms/step - loss: 2.2232 - accuracy: 0.6776 - val_loss: 4.3722 - val_accuracy: 0.4552\n",
      "Epoch 88/170\n",
      "748/748 [==============================] - 68s 91ms/step - loss: 2.2058 - accuracy: 0.6820 - val_loss: 4.3950 - val_accuracy: 0.4490\n",
      "Epoch 89/170\n",
      "748/748 [==============================] - 68s 91ms/step - loss: 2.1988 - accuracy: 0.6840 - val_loss: 4.4263 - val_accuracy: 0.4480\n",
      "Epoch 90/170\n",
      "748/748 [==============================] - ETA: 0s - loss: 2.1926 - accuracy: 0.6827\n",
      "Epoch 00090: saving model to /home/jupyter/workspace/Documents/music-generator/research/models/emb-generator-90-2.192636013031006\n",
      "INFO:tensorflow:Assets written to: /home/jupyter/workspace/Documents/music-generator/research/models/emb-generator-90-2.192636013031006/assets\n",
      "748/748 [==============================] - 87s 116ms/step - loss: 2.1926 - accuracy: 0.6827 - val_loss: 4.3912 - val_accuracy: 0.4524\n",
      "Epoch 91/170\n",
      "748/748 [==============================] - 68s 91ms/step - loss: 2.1829 - accuracy: 0.6846 - val_loss: 4.4138 - val_accuracy: 0.4478\n",
      "Epoch 92/170\n",
      "748/748 [==============================] - 68s 91ms/step - loss: 2.1809 - accuracy: 0.6856 - val_loss: 4.4352 - val_accuracy: 0.4500\n",
      "Epoch 93/170\n",
      "748/748 [==============================] - 68s 91ms/step - loss: 2.1609 - accuracy: 0.6886 - val_loss: 4.4332 - val_accuracy: 0.4485\n",
      "Epoch 94/170\n",
      "748/748 [==============================] - 68s 91ms/step - loss: 2.1641 - accuracy: 0.6893 - val_loss: 4.4219 - val_accuracy: 0.4498\n",
      "Epoch 95/170\n",
      "748/748 [==============================] - 68s 91ms/step - loss: 2.1609 - accuracy: 0.6900 - val_loss: 4.4352 - val_accuracy: 0.4564\n",
      "Epoch 96/170\n",
      "748/748 [==============================] - 68s 91ms/step - loss: 2.1579 - accuracy: 0.6929 - val_loss: 4.4294 - val_accuracy: 0.4523\n",
      "Epoch 97/170\n",
      "748/748 [==============================] - 68s 91ms/step - loss: 2.1449 - accuracy: 0.6941 - val_loss: 4.3971 - val_accuracy: 0.4496\n",
      "Epoch 98/170\n",
      "748/748 [==============================] - 68s 91ms/step - loss: 2.1401 - accuracy: 0.6959 - val_loss: 4.3751 - val_accuracy: 0.4585\n",
      "Epoch 99/170\n",
      "748/748 [==============================] - 68s 91ms/step - loss: 2.1324 - accuracy: 0.6941 - val_loss: 4.4408 - val_accuracy: 0.4522\n",
      "Epoch 100/170\n",
      "748/748 [==============================] - ETA: 0s - loss: 2.1267 - accuracy: 0.6953\n",
      "Epoch 00100: saving model to /home/jupyter/workspace/Documents/music-generator/research/models/emb-generator-100-2.1266863346099854\n",
      "INFO:tensorflow:Assets written to: /home/jupyter/workspace/Documents/music-generator/research/models/emb-generator-100-2.1266863346099854/assets\n",
      "748/748 [==============================] - 87s 116ms/step - loss: 2.1267 - accuracy: 0.6953 - val_loss: 4.4245 - val_accuracy: 0.4516\n",
      "Epoch 101/170\n",
      "748/748 [==============================] - 68s 91ms/step - loss: 2.1212 - accuracy: 0.6954 - val_loss: 4.4336 - val_accuracy: 0.4542\n",
      "Epoch 102/170\n",
      "748/748 [==============================] - 68s 91ms/step - loss: 2.1277 - accuracy: 0.6942 - val_loss: 4.4275 - val_accuracy: 0.4491\n",
      "Epoch 103/170\n",
      "748/748 [==============================] - 68s 91ms/step - loss: 2.1121 - accuracy: 0.6974 - val_loss: 4.4718 - val_accuracy: 0.4579\n",
      "Epoch 104/170\n",
      "748/748 [==============================] - 68s 91ms/step - loss: 2.1130 - accuracy: 0.6978 - val_loss: 4.4271 - val_accuracy: 0.4541\n",
      "Epoch 105/170\n",
      "748/748 [==============================] - 68s 91ms/step - loss: 2.1086 - accuracy: 0.6975 - val_loss: 4.4258 - val_accuracy: 0.4549\n",
      "Epoch 106/170\n",
      "748/748 [==============================] - 68s 91ms/step - loss: 2.0992 - accuracy: 0.6987 - val_loss: 4.4520 - val_accuracy: 0.4545\n",
      "Epoch 107/170\n",
      "748/748 [==============================] - 68s 91ms/step - loss: 2.0969 - accuracy: 0.6986 - val_loss: 4.4604 - val_accuracy: 0.4532\n",
      "Epoch 108/170\n",
      "748/748 [==============================] - 68s 91ms/step - loss: 2.0892 - accuracy: 0.7003 - val_loss: 4.4391 - val_accuracy: 0.4623\n",
      "Epoch 109/170\n",
      "748/748 [==============================] - 68s 91ms/step - loss: 2.0791 - accuracy: 0.7025 - val_loss: 4.4418 - val_accuracy: 0.4609\n",
      "Epoch 110/170\n",
      "748/748 [==============================] - ETA: 0s - loss: 2.0896 - accuracy: 0.7016\n",
      "Epoch 00110: saving model to /home/jupyter/workspace/Documents/music-generator/research/models/emb-generator-110-2.0895841121673584\n",
      "INFO:tensorflow:Assets written to: /home/jupyter/workspace/Documents/music-generator/research/models/emb-generator-110-2.0895841121673584/assets\n",
      "748/748 [==============================] - 87s 116ms/step - loss: 2.0896 - accuracy: 0.7016 - val_loss: 4.4412 - val_accuracy: 0.4555\n",
      "Epoch 111/170\n",
      "748/748 [==============================] - 68s 91ms/step - loss: 2.0736 - accuracy: 0.7047 - val_loss: 4.4652 - val_accuracy: 0.4537\n",
      "Epoch 112/170\n",
      "748/748 [==============================] - 68s 91ms/step - loss: 2.0834 - accuracy: 0.7008 - val_loss: 4.4370 - val_accuracy: 0.4572\n",
      "Epoch 113/170\n",
      "748/748 [==============================] - 68s 91ms/step - loss: 2.0666 - accuracy: 0.7038 - val_loss: 4.5148 - val_accuracy: 0.4539\n",
      "Epoch 114/170\n",
      "748/748 [==============================] - 68s 91ms/step - loss: 2.0688 - accuracy: 0.7027 - val_loss: 4.4673 - val_accuracy: 0.4557\n",
      "Epoch 115/170\n",
      "748/748 [==============================] - 68s 91ms/step - loss: 2.0669 - accuracy: 0.7040 - val_loss: 4.4662 - val_accuracy: 0.4548\n",
      "Epoch 116/170\n",
      "748/748 [==============================] - 68s 91ms/step - loss: 2.0533 - accuracy: 0.7055 - val_loss: 4.4615 - val_accuracy: 0.4546\n",
      "Epoch 117/170\n",
      "748/748 [==============================] - 68s 91ms/step - loss: 2.0478 - accuracy: 0.7049 - val_loss: 4.4663 - val_accuracy: 0.4544\n",
      "Epoch 118/170\n",
      "748/748 [==============================] - 68s 91ms/step - loss: 2.0549 - accuracy: 0.7064 - val_loss: 4.4775 - val_accuracy: 0.4574\n",
      "Epoch 119/170\n",
      "748/748 [==============================] - 68s 91ms/step - loss: 2.0400 - accuracy: 0.7083 - val_loss: 4.5188 - val_accuracy: 0.4538\n",
      "Epoch 120/170\n",
      "748/748 [==============================] - ETA: 0s - loss: 2.0448 - accuracy: 0.7052\n",
      "Epoch 00120: saving model to /home/jupyter/workspace/Documents/music-generator/research/models/emb-generator-120-2.0448083877563477\n",
      "INFO:tensorflow:Assets written to: /home/jupyter/workspace/Documents/music-generator/research/models/emb-generator-120-2.0448083877563477/assets\n",
      "748/748 [==============================] - 87s 116ms/step - loss: 2.0448 - accuracy: 0.7052 - val_loss: 4.4706 - val_accuracy: 0.4557\n",
      "Epoch 121/170\n",
      "748/748 [==============================] - 68s 91ms/step - loss: 2.0279 - accuracy: 0.7098 - val_loss: 4.5458 - val_accuracy: 0.4548\n",
      "Epoch 122/170\n",
      "748/748 [==============================] - 68s 91ms/step - loss: 2.0265 - accuracy: 0.7092 - val_loss: 4.4857 - val_accuracy: 0.4548\n",
      "Epoch 123/170\n",
      "748/748 [==============================] - 68s 91ms/step - loss: 2.0359 - accuracy: 0.7101 - val_loss: 4.4536 - val_accuracy: 0.4586\n",
      "Epoch 124/170\n",
      "748/748 [==============================] - 68s 91ms/step - loss: 2.0306 - accuracy: 0.7102 - val_loss: 4.4371 - val_accuracy: 0.4607\n",
      "Epoch 125/170\n",
      "748/748 [==============================] - 68s 91ms/step - loss: 2.0246 - accuracy: 0.7105 - val_loss: 4.4703 - val_accuracy: 0.4573\n",
      "Epoch 126/170\n",
      "748/748 [==============================] - 68s 91ms/step - loss: 2.0364 - accuracy: 0.7085 - val_loss: 4.5054 - val_accuracy: 0.4571\n",
      "Epoch 127/170\n",
      "748/748 [==============================] - 68s 91ms/step - loss: 2.0257 - accuracy: 0.7107 - val_loss: 4.5082 - val_accuracy: 0.4553\n",
      "Epoch 128/170\n",
      "748/748 [==============================] - 68s 91ms/step - loss: 2.0324 - accuracy: 0.7097 - val_loss: 4.5643 - val_accuracy: 0.4503\n",
      "Epoch 129/170\n",
      "748/748 [==============================] - 68s 91ms/step - loss: 2.0227 - accuracy: 0.7087 - val_loss: 4.4823 - val_accuracy: 0.4587\n",
      "Epoch 130/170\n",
      "748/748 [==============================] - ETA: 0s - loss: 2.0211 - accuracy: 0.7113\n",
      "Epoch 00130: saving model to /home/jupyter/workspace/Documents/music-generator/research/models/emb-generator-130-2.0211050510406494\n",
      "INFO:tensorflow:Assets written to: /home/jupyter/workspace/Documents/music-generator/research/models/emb-generator-130-2.0211050510406494/assets\n",
      "748/748 [==============================] - 87s 116ms/step - loss: 2.0211 - accuracy: 0.7113 - val_loss: 4.5013 - val_accuracy: 0.4535\n",
      "Epoch 131/170\n",
      "748/748 [==============================] - 68s 91ms/step - loss: 1.9966 - accuracy: 0.7142 - val_loss: 4.5964 - val_accuracy: 0.4500\n",
      "Epoch 132/170\n",
      "748/748 [==============================] - 68s 91ms/step - loss: 2.0141 - accuracy: 0.7113 - val_loss: 4.5266 - val_accuracy: 0.4562\n",
      "Epoch 133/170\n",
      "748/748 [==============================] - 68s 91ms/step - loss: 2.0098 - accuracy: 0.7106 - val_loss: 4.4981 - val_accuracy: 0.4560\n",
      "Epoch 134/170\n",
      "748/748 [==============================] - 68s 91ms/step - loss: 2.0197 - accuracy: 0.7095 - val_loss: 4.5225 - val_accuracy: 0.4548\n",
      "Epoch 135/170\n",
      "748/748 [==============================] - 68s 91ms/step - loss: 2.0090 - accuracy: 0.7106 - val_loss: 4.5652 - val_accuracy: 0.4537\n",
      "Epoch 136/170\n",
      "748/748 [==============================] - 68s 91ms/step - loss: 2.0133 - accuracy: 0.7098 - val_loss: 4.5307 - val_accuracy: 0.4533\n",
      "Epoch 137/170\n",
      "748/748 [==============================] - 68s 91ms/step - loss: 2.0054 - accuracy: 0.7115 - val_loss: 4.5547 - val_accuracy: 0.4526\n",
      "Epoch 138/170\n",
      "748/748 [==============================] - 68s 91ms/step - loss: 2.0099 - accuracy: 0.7106 - val_loss: 4.5677 - val_accuracy: 0.4520\n",
      "Epoch 139/170\n",
      "748/748 [==============================] - 68s 91ms/step - loss: 2.0113 - accuracy: 0.7113 - val_loss: 4.5423 - val_accuracy: 0.4528\n",
      "Epoch 140/170\n",
      "748/748 [==============================] - ETA: 0s - loss: 1.9999 - accuracy: 0.7140\n",
      "Epoch 00140: saving model to /home/jupyter/workspace/Documents/music-generator/research/models/emb-generator-140-1.9999338388442993\n",
      "INFO:tensorflow:Assets written to: /home/jupyter/workspace/Documents/music-generator/research/models/emb-generator-140-1.9999338388442993/assets\n",
      "748/748 [==============================] - 87s 116ms/step - loss: 1.9999 - accuracy: 0.7140 - val_loss: 4.5071 - val_accuracy: 0.4553\n",
      "Epoch 141/170\n",
      "748/748 [==============================] - 68s 91ms/step - loss: 2.0014 - accuracy: 0.7117 - val_loss: 4.5684 - val_accuracy: 0.4518\n",
      "Epoch 142/170\n",
      "748/748 [==============================] - 68s 91ms/step - loss: 1.9986 - accuracy: 0.7118 - val_loss: 4.5167 - val_accuracy: 0.4571\n",
      "Epoch 143/170\n",
      "748/748 [==============================] - 68s 91ms/step - loss: 1.9979 - accuracy: 0.7093 - val_loss: 4.5768 - val_accuracy: 0.4573\n",
      "Epoch 144/170\n",
      "748/748 [==============================] - 68s 91ms/step - loss: 1.9995 - accuracy: 0.7124 - val_loss: 4.5691 - val_accuracy: 0.4563\n",
      "Epoch 145/170\n",
      "748/748 [==============================] - 68s 91ms/step - loss: 2.0099 - accuracy: 0.7114 - val_loss: 4.5501 - val_accuracy: 0.4535\n",
      "Epoch 146/170\n",
      "748/748 [==============================] - 68s 91ms/step - loss: 1.9800 - accuracy: 0.7130 - val_loss: 4.5881 - val_accuracy: 0.4504\n",
      "Epoch 147/170\n",
      "748/748 [==============================] - 68s 91ms/step - loss: 2.0236 - accuracy: 0.7070 - val_loss: 4.5757 - val_accuracy: 0.4518\n",
      "Epoch 148/170\n",
      "748/748 [==============================] - 68s 91ms/step - loss: 2.0038 - accuracy: 0.7107 - val_loss: 4.6014 - val_accuracy: 0.4547\n",
      "Epoch 149/170\n",
      "748/748 [==============================] - 68s 91ms/step - loss: 2.0004 - accuracy: 0.7109 - val_loss: 4.6155 - val_accuracy: 0.4491\n",
      "Epoch 150/170\n",
      "748/748 [==============================] - ETA: 0s - loss: 2.0077 - accuracy: 0.7080\n",
      "Epoch 00150: saving model to /home/jupyter/workspace/Documents/music-generator/research/models/emb-generator-150-2.007676839828491\n",
      "INFO:tensorflow:Assets written to: /home/jupyter/workspace/Documents/music-generator/research/models/emb-generator-150-2.007676839828491/assets\n",
      "748/748 [==============================] - 87s 116ms/step - loss: 2.0077 - accuracy: 0.7080 - val_loss: 4.5729 - val_accuracy: 0.4553\n",
      "Epoch 151/170\n",
      "748/748 [==============================] - 68s 91ms/step - loss: 2.0078 - accuracy: 0.7121 - val_loss: 4.5846 - val_accuracy: 0.4557\n",
      "Epoch 152/170\n",
      "748/748 [==============================] - 68s 91ms/step - loss: 2.0120 - accuracy: 0.7110 - val_loss: 4.6284 - val_accuracy: 0.4478\n",
      "Epoch 153/170\n",
      "748/748 [==============================] - 68s 91ms/step - loss: 2.0101 - accuracy: 0.7111 - val_loss: 4.6476 - val_accuracy: 0.4446\n",
      "Epoch 154/170\n",
      "748/748 [==============================] - 68s 91ms/step - loss: 2.0110 - accuracy: 0.7081 - val_loss: 4.6217 - val_accuracy: 0.4527\n",
      "Epoch 155/170\n",
      "748/748 [==============================] - 68s 91ms/step - loss: 2.0084 - accuracy: 0.7110 - val_loss: 4.6289 - val_accuracy: 0.4472\n",
      "Epoch 156/170\n",
      "748/748 [==============================] - 68s 91ms/step - loss: 2.0149 - accuracy: 0.7074 - val_loss: 4.5961 - val_accuracy: 0.4487\n",
      "Epoch 157/170\n",
      "748/748 [==============================] - 68s 91ms/step - loss: 2.0159 - accuracy: 0.7093 - val_loss: 4.6261 - val_accuracy: 0.4480\n",
      "Epoch 158/170\n",
      "748/748 [==============================] - 68s 91ms/step - loss: 2.0073 - accuracy: 0.7092 - val_loss: 4.6230 - val_accuracy: 0.4488\n",
      "Epoch 159/170\n",
      "748/748 [==============================] - 68s 91ms/step - loss: 2.0213 - accuracy: 0.7083 - val_loss: 4.6681 - val_accuracy: 0.4432\n",
      "Epoch 160/170\n",
      "748/748 [==============================] - ETA: 0s - loss: 2.0337 - accuracy: 0.7038\n",
      "Epoch 00160: saving model to /home/jupyter/workspace/Documents/music-generator/research/models/emb-generator-160-2.0337445735931396\n",
      "INFO:tensorflow:Assets written to: /home/jupyter/workspace/Documents/music-generator/research/models/emb-generator-160-2.0337445735931396/assets\n",
      "748/748 [==============================] - 87s 116ms/step - loss: 2.0337 - accuracy: 0.7038 - val_loss: 4.6228 - val_accuracy: 0.4456\n",
      "Epoch 161/170\n",
      "748/748 [==============================] - 68s 91ms/step - loss: 2.0339 - accuracy: 0.7053 - val_loss: 4.6352 - val_accuracy: 0.4434\n",
      "Epoch 162/170\n",
      "748/748 [==============================] - 68s 91ms/step - loss: 2.0219 - accuracy: 0.7055 - val_loss: 4.7010 - val_accuracy: 0.4399\n",
      "Epoch 163/170\n",
      "748/748 [==============================] - 68s 91ms/step - loss: 2.0187 - accuracy: 0.7054 - val_loss: 4.6620 - val_accuracy: 0.4467\n",
      "Epoch 164/170\n",
      "748/748 [==============================] - 68s 91ms/step - loss: 2.0298 - accuracy: 0.7035 - val_loss: 4.6643 - val_accuracy: 0.4475\n",
      "Epoch 165/170\n",
      "748/748 [==============================] - 68s 91ms/step - loss: 2.0386 - accuracy: 0.7028 - val_loss: 4.6696 - val_accuracy: 0.4448\n",
      "Epoch 166/170\n",
      "748/748 [==============================] - 68s 91ms/step - loss: 2.0404 - accuracy: 0.7031 - val_loss: 4.7342 - val_accuracy: 0.4370\n",
      "Epoch 167/170\n",
      "748/748 [==============================] - 68s 91ms/step - loss: 2.0455 - accuracy: 0.7011 - val_loss: 4.6921 - val_accuracy: 0.4405\n",
      "Epoch 168/170\n",
      "748/748 [==============================] - 68s 91ms/step - loss: 2.0485 - accuracy: 0.6974 - val_loss: 4.6826 - val_accuracy: 0.4377\n",
      "Epoch 169/170\n",
      "748/748 [==============================] - 68s 91ms/step - loss: 2.0569 - accuracy: 0.6993 - val_loss: 4.6941 - val_accuracy: 0.4421\n",
      "Epoch 170/170\n",
      "748/748 [==============================] - ETA: 0s - loss: 2.0616 - accuracy: 0.6964\n",
      "Epoch 00170: saving model to /home/jupyter/workspace/Documents/music-generator/research/models/emb-generator-170-2.0615596771240234\n",
      "INFO:tensorflow:Assets written to: /home/jupyter/workspace/Documents/music-generator/research/models/emb-generator-170-2.0615596771240234/assets\n",
      "748/748 [==============================] - 87s 116ms/step - loss: 2.0616 - accuracy: 0.6964 - val_loss: 4.6895 - val_accuracy: 0.4426\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f88ce00a9b0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "config = tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "train_x, test_x, train_y, test_y = train_test_split(X, Y, shuffle=True)\n",
    "emb_generator: EmbChordGeneratorMusicModel = EmbChordGeneratorMusicModel(generator_seq_len, len(tokenizer.word_index))\n",
    "checkpoint: ModelCheckpoint = ModelCheckpoint(\n",
    "    os.path.abspath(\"./models/emb-generator-{epoch}-{loss}\"),\n",
    "    period=10,\n",
    "    monitor='loss',\n",
    "    verbose=1,\n",
    "    save_best_only=False,\n",
    "    mode='min'\n",
    ")\n",
    "emb_generator.fit(train_x, train_y, epochs=170, batch_size=64, callbacks=[checkpoint], validation_data=(test_x, test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleEmbChordGeneratorMusicModel:\n",
    "    def __init__(self, seq_len: int, chords_vocab_size: int):\n",
    "        random.set_seed(RANDOM_STATE)\n",
    "        chords_input = Input(shape=seq_len)\n",
    "        embedding = Embedding(chords_vocab_size + 1, 100)(chords_input)\n",
    "        bilstm = Bidirectional(LSTM(512, return_sequences=True))(embedding)\n",
    "        dropout = Dropout(0.3)(bilstm)\n",
    "        lstm = LSTM(1024, return_sequences=True)(dropout)\n",
    "        dropout = Dropout(0.3)(lstm)\n",
    "        lstm = LSTM(512, return_sequences=True)(dropout)\n",
    "        pool = GlobalAveragePooling1D()(lstm)\n",
    "        dense = Dense(512)(pool)\n",
    "        chord_output = Dense(chords_vocab_size + 1, activation=\"softmax\")(dense)\n",
    "        self._model = Model(chords_input, chord_output)\n",
    "        self._model.compile(loss='sparse_categorical_crossentropy', optimizer='rmsprop', metrics=[\"accuracy\"])\n",
    "\n",
    "    def fit(self, train_x, train_y, **kwargs):\n",
    "        return self._model.fit(train_x, train_y, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/100\n",
      "748/748 [==============================] - 66s 89ms/step - loss: 6.3979 - accuracy: 0.0229 - val_loss: 6.1689 - val_accuracy: 0.0283\n",
      "Epoch 2/100\n",
      "748/748 [==============================] - 65s 87ms/step - loss: 6.1497 - accuracy: 0.0281 - val_loss: 6.0418 - val_accuracy: 0.0343\n",
      "Epoch 3/100\n",
      "748/748 [==============================] - 65s 87ms/step - loss: 5.9624 - accuracy: 0.0383 - val_loss: 5.8686 - val_accuracy: 0.0439\n",
      "Epoch 4/100\n",
      "748/748 [==============================] - 65s 87ms/step - loss: 5.7911 - accuracy: 0.0489 - val_loss: 5.6926 - val_accuracy: 0.0589\n",
      "Epoch 5/100\n",
      "748/748 [==============================] - 65s 87ms/step - loss: 5.6152 - accuracy: 0.0680 - val_loss: 5.6389 - val_accuracy: 0.0693\n",
      "Epoch 6/100\n",
      "748/748 [==============================] - 65s 87ms/step - loss: 5.4015 - accuracy: 0.0878 - val_loss: 5.4164 - val_accuracy: 0.0965\n",
      "Epoch 7/100\n",
      "748/748 [==============================] - 65s 87ms/step - loss: 5.1839 - accuracy: 0.1102 - val_loss: 5.1462 - val_accuracy: 0.1195\n",
      "Epoch 8/100\n",
      "748/748 [==============================] - 65s 87ms/step - loss: 4.9606 - accuracy: 0.1305 - val_loss: 5.0409 - val_accuracy: 0.1242\n",
      "Epoch 9/100\n",
      "748/748 [==============================] - 65s 87ms/step - loss: 4.7391 - accuracy: 0.1533 - val_loss: 4.8379 - val_accuracy: 0.1474\n",
      "Epoch 10/100\n",
      "748/748 [==============================] - ETA: 0s - loss: 4.5423 - accuracy: 0.1716\n",
      "Epoch 00010: saving model to /home/jupyter/workspace/Documents/music-generator/research/models/simple-generator-10-4.542335033416748\n",
      "INFO:tensorflow:Assets written to: /home/jupyter/workspace/Documents/music-generator/research/models/simple-generator-10-4.542335033416748/assets\n",
      "748/748 [==============================] - 83s 111ms/step - loss: 4.5423 - accuracy: 0.1716 - val_loss: 4.7448 - val_accuracy: 0.1580\n",
      "Epoch 11/100\n",
      "748/748 [==============================] - 65s 87ms/step - loss: 4.3623 - accuracy: 0.1885 - val_loss: 4.6014 - val_accuracy: 0.1748\n",
      "Epoch 12/100\n",
      "748/748 [==============================] - 65s 87ms/step - loss: 4.1911 - accuracy: 0.2110 - val_loss: 4.5139 - val_accuracy: 0.1832\n",
      "Epoch 13/100\n",
      "748/748 [==============================] - 65s 87ms/step - loss: 4.0521 - accuracy: 0.2284 - val_loss: 4.4930 - val_accuracy: 0.1958\n",
      "Epoch 14/100\n",
      "748/748 [==============================] - 65s 87ms/step - loss: 3.9554 - accuracy: 0.2483 - val_loss: 4.5187 - val_accuracy: 0.2088\n",
      "Epoch 15/100\n",
      "748/748 [==============================] - 65s 87ms/step - loss: 3.9341 - accuracy: 0.2670 - val_loss: 4.5953 - val_accuracy: 0.2133\n",
      "Epoch 16/100\n",
      "748/748 [==============================] - 65s 87ms/step - loss: 3.9778 - accuracy: 0.2842 - val_loss: 4.6554 - val_accuracy: 0.2280\n",
      "Epoch 17/100\n",
      "748/748 [==============================] - 65s 87ms/step - loss: 3.9204 - accuracy: 0.3050 - val_loss: 4.6075 - val_accuracy: 0.2370\n",
      "Epoch 18/100\n",
      "748/748 [==============================] - 65s 87ms/step - loss: 3.8127 - accuracy: 0.3219 - val_loss: 4.6113 - val_accuracy: 0.2410\n",
      "Epoch 19/100\n",
      "748/748 [==============================] - 65s 87ms/step - loss: 3.7114 - accuracy: 0.3417 - val_loss: 4.5811 - val_accuracy: 0.2525\n",
      "Epoch 20/100\n",
      "748/748 [==============================] - ETA: 0s - loss: 3.6145 - accuracy: 0.3616\n",
      "Epoch 00020: saving model to /home/jupyter/workspace/Documents/music-generator/research/models/simple-generator-20-3.6145336627960205\n",
      "INFO:tensorflow:Assets written to: /home/jupyter/workspace/Documents/music-generator/research/models/simple-generator-20-3.6145336627960205/assets\n",
      "748/748 [==============================] - 83s 110ms/step - loss: 3.6145 - accuracy: 0.3616 - val_loss: 4.5630 - val_accuracy: 0.2643\n",
      "Epoch 21/100\n",
      "748/748 [==============================] - 65s 87ms/step - loss: 3.5294 - accuracy: 0.3818 - val_loss: 4.5407 - val_accuracy: 0.2705\n",
      "Epoch 22/100\n",
      "748/748 [==============================] - 67s 89ms/step - loss: 3.4416 - accuracy: 0.3975 - val_loss: 4.5151 - val_accuracy: 0.2783\n",
      "Epoch 23/100\n",
      "748/748 [==============================] - 65s 87ms/step - loss: 3.3681 - accuracy: 0.4151 - val_loss: 4.4835 - val_accuracy: 0.2880\n",
      "Epoch 24/100\n",
      "748/748 [==============================] - 65s 87ms/step - loss: 3.2740 - accuracy: 0.4346 - val_loss: 4.5197 - val_accuracy: 0.2957\n",
      "Epoch 25/100\n",
      "748/748 [==============================] - 65s 87ms/step - loss: 3.2138 - accuracy: 0.4478 - val_loss: 4.4790 - val_accuracy: 0.2994\n",
      "Epoch 26/100\n",
      "748/748 [==============================] - 65s 87ms/step - loss: 3.1493 - accuracy: 0.4602 - val_loss: 4.4630 - val_accuracy: 0.3103\n",
      "Epoch 27/100\n",
      "748/748 [==============================] - 65s 87ms/step - loss: 3.1010 - accuracy: 0.4739 - val_loss: 4.4855 - val_accuracy: 0.3114\n",
      "Epoch 28/100\n",
      "748/748 [==============================] - 65s 87ms/step - loss: 3.0392 - accuracy: 0.4882 - val_loss: 4.4638 - val_accuracy: 0.3187\n",
      "Epoch 29/100\n",
      "748/748 [==============================] - 65s 87ms/step - loss: 2.9958 - accuracy: 0.4970 - val_loss: 4.4379 - val_accuracy: 0.3278\n",
      "Epoch 30/100\n",
      "748/748 [==============================] - ETA: 0s - loss: 2.9566 - accuracy: 0.5071\n",
      "Epoch 00030: saving model to /home/jupyter/workspace/Documents/music-generator/research/models/simple-generator-30-2.956599712371826\n",
      "INFO:tensorflow:Assets written to: /home/jupyter/workspace/Documents/music-generator/research/models/simple-generator-30-2.956599712371826/assets\n",
      "748/748 [==============================] - 83s 110ms/step - loss: 2.9566 - accuracy: 0.5071 - val_loss: 4.4786 - val_accuracy: 0.3295\n",
      "Epoch 31/100\n",
      "748/748 [==============================] - 65s 87ms/step - loss: 2.9151 - accuracy: 0.5168 - val_loss: 4.4614 - val_accuracy: 0.3272\n",
      "Epoch 32/100\n",
      "748/748 [==============================] - 65s 87ms/step - loss: 2.8645 - accuracy: 0.5302 - val_loss: 4.4501 - val_accuracy: 0.3406\n",
      "Epoch 33/100\n",
      "748/748 [==============================] - 65s 87ms/step - loss: 2.8350 - accuracy: 0.5359 - val_loss: 4.4535 - val_accuracy: 0.3381\n",
      "Epoch 34/100\n",
      "748/748 [==============================] - 65s 87ms/step - loss: 2.8128 - accuracy: 0.5401 - val_loss: 4.4757 - val_accuracy: 0.3452\n",
      "Epoch 35/100\n",
      "748/748 [==============================] - 65s 87ms/step - loss: 2.7816 - accuracy: 0.5503 - val_loss: 4.4538 - val_accuracy: 0.3482\n",
      "Epoch 36/100\n",
      "748/748 [==============================] - 65s 87ms/step - loss: 2.7540 - accuracy: 0.5576 - val_loss: 4.4720 - val_accuracy: 0.3461\n",
      "Epoch 37/100\n",
      "748/748 [==============================] - 65s 87ms/step - loss: 2.7344 - accuracy: 0.5632 - val_loss: 4.4841 - val_accuracy: 0.3497\n",
      "Epoch 38/100\n",
      "748/748 [==============================] - 65s 87ms/step - loss: 2.7125 - accuracy: 0.5692 - val_loss: 4.5001 - val_accuracy: 0.3486\n",
      "Epoch 39/100\n",
      "748/748 [==============================] - 65s 87ms/step - loss: 2.6897 - accuracy: 0.5723 - val_loss: 4.4200 - val_accuracy: 0.3574\n",
      "Epoch 40/100\n",
      "748/748 [==============================] - ETA: 0s - loss: 2.6637 - accuracy: 0.5800\n",
      "Epoch 00040: saving model to /home/jupyter/workspace/Documents/music-generator/research/models/simple-generator-40-2.663702964782715\n",
      "INFO:tensorflow:Assets written to: /home/jupyter/workspace/Documents/music-generator/research/models/simple-generator-40-2.663702964782715/assets\n",
      "748/748 [==============================] - 82s 110ms/step - loss: 2.6637 - accuracy: 0.5800 - val_loss: 4.4749 - val_accuracy: 0.3611\n",
      "Epoch 41/100\n",
      "748/748 [==============================] - 65s 87ms/step - loss: 2.6515 - accuracy: 0.5836 - val_loss: 4.4827 - val_accuracy: 0.3612\n",
      "Epoch 42/100\n",
      "748/748 [==============================] - 65s 87ms/step - loss: 2.6302 - accuracy: 0.5861 - val_loss: 4.4660 - val_accuracy: 0.3571\n",
      "Epoch 43/100\n",
      "748/748 [==============================] - 65s 87ms/step - loss: 2.6091 - accuracy: 0.5885 - val_loss: 4.4385 - val_accuracy: 0.3657\n",
      "Epoch 44/100\n",
      "748/748 [==============================] - 65s 87ms/step - loss: 2.5677 - accuracy: 0.5966 - val_loss: 4.4205 - val_accuracy: 0.3672\n",
      "Epoch 45/100\n",
      "748/748 [==============================] - 65s 87ms/step - loss: 2.5546 - accuracy: 0.6004 - val_loss: 4.4483 - val_accuracy: 0.3687\n",
      "Epoch 46/100\n",
      "748/748 [==============================] - 65s 87ms/step - loss: 2.5546 - accuracy: 0.6013 - val_loss: 4.4766 - val_accuracy: 0.3669\n",
      "Epoch 47/100\n",
      "748/748 [==============================] - 65s 87ms/step - loss: 2.5361 - accuracy: 0.6055 - val_loss: 4.4646 - val_accuracy: 0.3664\n",
      "Epoch 48/100\n",
      "748/748 [==============================] - 65s 87ms/step - loss: 2.5265 - accuracy: 0.6080 - val_loss: 4.4298 - val_accuracy: 0.3724\n",
      "Epoch 49/100\n",
      "748/748 [==============================] - 65s 87ms/step - loss: 2.5217 - accuracy: 0.6060 - val_loss: 4.4796 - val_accuracy: 0.3688\n",
      "Epoch 50/100\n",
      "748/748 [==============================] - ETA: 0s - loss: 2.5255 - accuracy: 0.6099\n",
      "Epoch 00050: saving model to /home/jupyter/workspace/Documents/music-generator/research/models/simple-generator-50-2.525465965270996\n",
      "INFO:tensorflow:Assets written to: /home/jupyter/workspace/Documents/music-generator/research/models/simple-generator-50-2.525465965270996/assets\n",
      "748/748 [==============================] - 84s 113ms/step - loss: 2.5255 - accuracy: 0.6099 - val_loss: 4.4570 - val_accuracy: 0.3689\n",
      "Epoch 51/100\n",
      "748/748 [==============================] - 65s 87ms/step - loss: 2.5309 - accuracy: 0.6101 - val_loss: 4.4539 - val_accuracy: 0.3722\n",
      "Epoch 52/100\n",
      "748/748 [==============================] - 65s 87ms/step - loss: 2.5275 - accuracy: 0.6068 - val_loss: 4.4959 - val_accuracy: 0.3705\n",
      "Epoch 53/100\n",
      "748/748 [==============================] - 65s 87ms/step - loss: 2.5264 - accuracy: 0.6100 - val_loss: 4.5079 - val_accuracy: 0.3703\n",
      "Epoch 54/100\n",
      "748/748 [==============================] - 65s 87ms/step - loss: 2.5183 - accuracy: 0.6112 - val_loss: 4.4943 - val_accuracy: 0.3750\n",
      "Epoch 55/100\n",
      "748/748 [==============================] - 65s 87ms/step - loss: 2.5281 - accuracy: 0.6115 - val_loss: 4.4723 - val_accuracy: 0.3742\n",
      "Epoch 56/100\n",
      "748/748 [==============================] - 65s 87ms/step - loss: 2.5219 - accuracy: 0.6128 - val_loss: 4.5015 - val_accuracy: 0.3693\n",
      "Epoch 57/100\n",
      "748/748 [==============================] - 65s 87ms/step - loss: 2.5165 - accuracy: 0.6146 - val_loss: 4.5384 - val_accuracy: 0.3686\n",
      "Epoch 58/100\n",
      "748/748 [==============================] - 65s 87ms/step - loss: 2.5120 - accuracy: 0.6161 - val_loss: 4.5148 - val_accuracy: 0.3694\n",
      "Epoch 59/100\n",
      "748/748 [==============================] - 65s 87ms/step - loss: 2.5190 - accuracy: 0.6156 - val_loss: 4.5113 - val_accuracy: 0.3755\n",
      "Epoch 60/100\n",
      "748/748 [==============================] - ETA: 0s - loss: 2.5130 - accuracy: 0.6161\n",
      "Epoch 00060: saving model to /home/jupyter/workspace/Documents/music-generator/research/models/simple-generator-60-2.5129597187042236\n",
      "INFO:tensorflow:Assets written to: /home/jupyter/workspace/Documents/music-generator/research/models/simple-generator-60-2.5129597187042236/assets\n",
      "748/748 [==============================] - 82s 110ms/step - loss: 2.5130 - accuracy: 0.6161 - val_loss: 4.5120 - val_accuracy: 0.3739\n",
      "Epoch 61/100\n",
      "748/748 [==============================] - 65s 87ms/step - loss: 2.5212 - accuracy: 0.6155 - val_loss: 4.5282 - val_accuracy: 0.3776\n",
      "Epoch 62/100\n",
      "748/748 [==============================] - 65s 87ms/step - loss: 2.5199 - accuracy: 0.6160 - val_loss: 4.5321 - val_accuracy: 0.3783\n",
      "Epoch 63/100\n",
      "748/748 [==============================] - 65s 87ms/step - loss: 2.5296 - accuracy: 0.6173 - val_loss: 4.5595 - val_accuracy: 0.3646\n",
      "Epoch 64/100\n",
      "748/748 [==============================] - 65s 87ms/step - loss: 2.5473 - accuracy: 0.6122 - val_loss: 4.5594 - val_accuracy: 0.3748\n",
      "Epoch 65/100\n",
      "748/748 [==============================] - 65s 87ms/step - loss: 2.5353 - accuracy: 0.6143 - val_loss: 4.5171 - val_accuracy: 0.3797\n",
      "Epoch 66/100\n",
      "748/748 [==============================] - 65s 87ms/step - loss: 2.5375 - accuracy: 0.6127 - val_loss: 4.5562 - val_accuracy: 0.3744\n",
      "Epoch 67/100\n",
      "748/748 [==============================] - 65s 87ms/step - loss: 2.5507 - accuracy: 0.6130 - val_loss: 4.5980 - val_accuracy: 0.3694\n",
      "Epoch 68/100\n",
      "748/748 [==============================] - 65s 87ms/step - loss: 2.5647 - accuracy: 0.6090 - val_loss: 4.5740 - val_accuracy: 0.3731\n",
      "Epoch 69/100\n",
      "748/748 [==============================] - 65s 87ms/step - loss: 2.5923 - accuracy: 0.6059 - val_loss: 4.6086 - val_accuracy: 0.3721\n",
      "Epoch 70/100\n",
      "748/748 [==============================] - ETA: 0s - loss: 2.5841 - accuracy: 0.6054\n",
      "Epoch 00070: saving model to /home/jupyter/workspace/Documents/music-generator/research/models/simple-generator-70-2.584136486053467\n",
      "INFO:tensorflow:Assets written to: /home/jupyter/workspace/Documents/music-generator/research/models/simple-generator-70-2.584136486053467/assets\n",
      "748/748 [==============================] - 84s 113ms/step - loss: 2.5841 - accuracy: 0.6054 - val_loss: 4.5822 - val_accuracy: 0.3711\n",
      "Epoch 71/100\n",
      "748/748 [==============================] - 65s 87ms/step - loss: 2.5817 - accuracy: 0.6054 - val_loss: 4.6036 - val_accuracy: 0.3696\n",
      "Epoch 72/100\n",
      "748/748 [==============================] - 65s 87ms/step - loss: 2.5721 - accuracy: 0.6098 - val_loss: 4.6089 - val_accuracy: 0.3705\n",
      "Epoch 73/100\n",
      "748/748 [==============================] - 65s 87ms/step - loss: 2.5854 - accuracy: 0.6056 - val_loss: 4.6251 - val_accuracy: 0.3679\n",
      "Epoch 74/100\n",
      "748/748 [==============================] - 65s 87ms/step - loss: 2.6004 - accuracy: 0.6053 - val_loss: 4.6049 - val_accuracy: 0.3738\n",
      "Epoch 75/100\n",
      "748/748 [==============================] - 65s 87ms/step - loss: 2.5955 - accuracy: 0.6027 - val_loss: 4.5950 - val_accuracy: 0.3717\n",
      "Epoch 76/100\n",
      "748/748 [==============================] - 65s 87ms/step - loss: 2.5821 - accuracy: 0.6090 - val_loss: 4.6409 - val_accuracy: 0.3704\n",
      "Epoch 77/100\n",
      "748/748 [==============================] - 65s 87ms/step - loss: 2.5923 - accuracy: 0.6055 - val_loss: 4.6260 - val_accuracy: 0.3721\n",
      "Epoch 78/100\n",
      "748/748 [==============================] - 65s 87ms/step - loss: 2.6249 - accuracy: 0.5982 - val_loss: 4.6216 - val_accuracy: 0.3630\n",
      "Epoch 79/100\n",
      "748/748 [==============================] - 65s 87ms/step - loss: 2.6328 - accuracy: 0.5940 - val_loss: 4.6395 - val_accuracy: 0.3691\n",
      "Epoch 80/100\n",
      "748/748 [==============================] - ETA: 0s - loss: 2.6648 - accuracy: 0.5910\n",
      "Epoch 00080: saving model to /home/jupyter/workspace/Documents/music-generator/research/models/simple-generator-80-2.6647627353668213\n",
      "INFO:tensorflow:Assets written to: /home/jupyter/workspace/Documents/music-generator/research/models/simple-generator-80-2.6647627353668213/assets\n",
      "748/748 [==============================] - 82s 110ms/step - loss: 2.6648 - accuracy: 0.5910 - val_loss: 4.5759 - val_accuracy: 0.3692\n",
      "Epoch 81/100\n",
      "748/748 [==============================] - 65s 87ms/step - loss: 2.6409 - accuracy: 0.5939 - val_loss: 4.6494 - val_accuracy: 0.3672\n",
      "Epoch 82/100\n",
      "748/748 [==============================] - 65s 87ms/step - loss: 2.6764 - accuracy: 0.5861 - val_loss: 4.6495 - val_accuracy: 0.3657\n",
      "Epoch 83/100\n",
      "748/748 [==============================] - 65s 87ms/step - loss: 2.6966 - accuracy: 0.5844 - val_loss: 4.6221 - val_accuracy: 0.3683\n",
      "Epoch 84/100\n",
      "748/748 [==============================] - 65s 87ms/step - loss: 2.7027 - accuracy: 0.5831 - val_loss: 4.6386 - val_accuracy: 0.3645\n",
      "Epoch 85/100\n",
      "748/748 [==============================] - 65s 87ms/step - loss: 2.7593 - accuracy: 0.5727 - val_loss: 4.6585 - val_accuracy: 0.3570\n",
      "Epoch 86/100\n",
      "748/748 [==============================] - 65s 88ms/step - loss: 2.7592 - accuracy: 0.5708 - val_loss: 4.6480 - val_accuracy: 0.3658\n",
      "Epoch 87/100\n",
      "748/748 [==============================] - 65s 87ms/step - loss: 2.7510 - accuracy: 0.5735 - val_loss: 4.6257 - val_accuracy: 0.3597\n",
      "Epoch 88/100\n",
      "748/748 [==============================] - 65s 87ms/step - loss: 2.7649 - accuracy: 0.5685 - val_loss: 4.6508 - val_accuracy: 0.3612\n",
      "Epoch 89/100\n",
      "748/748 [==============================] - 65s 87ms/step - loss: 2.7769 - accuracy: 0.5671 - val_loss: 4.6593 - val_accuracy: 0.3575\n",
      "Epoch 90/100\n",
      "748/748 [==============================] - ETA: 0s - loss: 2.7656 - accuracy: 0.5721\n",
      "Epoch 00090: saving model to /home/jupyter/workspace/Documents/music-generator/research/models/simple-generator-90-2.765562057495117\n",
      "INFO:tensorflow:Assets written to: /home/jupyter/workspace/Documents/music-generator/research/models/simple-generator-90-2.765562057495117/assets\n",
      "748/748 [==============================] - 84s 112ms/step - loss: 2.7656 - accuracy: 0.5721 - val_loss: 4.6796 - val_accuracy: 0.3585\n",
      "Epoch 91/100\n",
      "748/748 [==============================] - 65s 87ms/step - loss: 2.7779 - accuracy: 0.5686 - val_loss: 4.7196 - val_accuracy: 0.3529\n",
      "Epoch 92/100\n",
      "748/748 [==============================] - 65s 87ms/step - loss: 2.8141 - accuracy: 0.5612 - val_loss: 4.6532 - val_accuracy: 0.3539\n",
      "Epoch 93/100\n",
      "748/748 [==============================] - 65s 87ms/step - loss: 2.8071 - accuracy: 0.5610 - val_loss: 4.6217 - val_accuracy: 0.3630\n",
      "Epoch 94/100\n",
      "748/748 [==============================] - 65s 87ms/step - loss: 2.8165 - accuracy: 0.5623 - val_loss: 4.6955 - val_accuracy: 0.3575\n",
      "Epoch 95/100\n",
      "748/748 [==============================] - 65s 87ms/step - loss: 2.8275 - accuracy: 0.5546 - val_loss: 4.7014 - val_accuracy: 0.3572\n",
      "Epoch 96/100\n",
      "748/748 [==============================] - 65s 87ms/step - loss: 2.8751 - accuracy: 0.5482 - val_loss: 4.7040 - val_accuracy: 0.3499\n",
      "Epoch 97/100\n",
      "748/748 [==============================] - 65s 87ms/step - loss: 2.9601 - accuracy: 0.5309 - val_loss: 4.7548 - val_accuracy: 0.3484\n",
      "Epoch 98/100\n",
      "748/748 [==============================] - 65s 87ms/step - loss: 2.9576 - accuracy: 0.5306 - val_loss: 4.7239 - val_accuracy: 0.3460\n",
      "Epoch 99/100\n",
      "748/748 [==============================] - 65s 87ms/step - loss: 2.9701 - accuracy: 0.5286 - val_loss: 4.6985 - val_accuracy: 0.3507\n",
      "Epoch 100/100\n",
      "748/748 [==============================] - ETA: 0s - loss: 2.9727 - accuracy: 0.5319\n",
      "Epoch 00100: saving model to /home/jupyter/workspace/Documents/music-generator/research/models/simple-generator-100-2.972742795944214\n",
      "INFO:tensorflow:Assets written to: /home/jupyter/workspace/Documents/music-generator/research/models/simple-generator-100-2.972742795944214/assets\n",
      "748/748 [==============================] - 83s 111ms/step - loss: 2.9727 - accuracy: 0.5319 - val_loss: 4.7124 - val_accuracy: 0.3508\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f87306da0f0>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "config = tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "simple_emb_generator: SimpleEmbChordGeneratorMusicModel = SimpleEmbChordGeneratorMusicModel(generator_seq_len, len(tokenizer.word_index))\n",
    "checkpoint: ModelCheckpoint = ModelCheckpoint(\n",
    "    os.path.abspath(\"./models/simple-generator-{epoch}-{loss}\"),\n",
    "    period=10,\n",
    "    monitor='loss',\n",
    "    verbose=1,\n",
    "    save_best_only=False,\n",
    "    mode='min'\n",
    ")\n",
    "simple_emb_generator.fit(train_x, train_y, epochs=100, batch_size=64, callbacks=[checkpoint], validation_data=(test_x, test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./models/emp-tokenizer.pckl\", \"wb\") as f:\n",
    "    pickle.dump(tokenizer, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
